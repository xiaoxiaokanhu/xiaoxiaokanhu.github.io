[{"title":"nginx https 证书配置","date":"2019-02-12T10:47:58.000Z","path":"2019/02/12/nginx-https-证书配置/","text":"使用https需要配置SSL证书,因为我使用的阿里云，所以下面是阿里云的配置 域名解析到服务器 申请ca证书在阿里云控制台-产品与服务-安全(云盾)-CA证书服务(数据安全)，点击购买证书选择“免费版DV SSL”，点击立即购买:然后点去支付:最后确认支付:就会回到管理界面,然后根据说明去配置。说明：因为我们这里申请的是开发版免费证书，所以一个证书仅支持一个域名认证，不支持通配符。等待几分钟，证书状态变为“已签发”后，证书就申请成功了。 下载证书列表中找到已签发的证书，下载, 下载的时候选择Nginx。然后把相应的正式传到服务器,命令方法使用scp。1$ scp -r root@43.224.34.73:/home/lk /root 参考nginx配置ssl证书实现https访问","tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"nginx http和https配置","date":"2019-02-12T10:23:28.000Z","path":"2019/02/12/nginx-http和https配置/","text":"nginx配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111### 全局配置##user www-data; ## 配置 worker 进程的用户和组worker_processes auto; ## 配置 worker 进程启动的数量，建议配置为 CPU 核心数error_log logs/error.log; ## 全局错误日志pid /run/nginx.pid; ## 设置记录主进程 ID 的文件worker_rlimit_nofile 8192; ## 配置一个工作进程能够接受并发连接的最大数### 工作模式及连接数上限##events &#123; # epoll 是多路复用 IO（I/O Multiplexing）中的一种方式， # 仅用于 Linux 2.6 以上内核，可以大大提高 Nginx 性能 use epoll # 单个后台 worker process 进程的最大并发链接数 # 并发总数 max_clients = worker_professes * worker_connections worker_connections 4096; ## Defaule: 1024 # multi_accept on; ## 指明 worker 进程立刻接受新的连接&#125;### http 模块##http &#123; ## # Basic Settings ## #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off， #以平衡磁盘与网络 I/O 处理速度，降低系统的 uptime. sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; ## 连接超时时间 types_hash_max_size 2048; ## 指定散列类型表的最大大小 # server_tokens off; # server_names_hash_bucket_size 64; # this seems to be required for some vhosts # server_name_in_redirect off; include /etc/nginx/mime.types; ## 设定 mine 类型 default_type application/octet-stream; # 设定请求缓冲 client_header_buffer_size 128k; # 指定客户端请求头缓存大小，当请求头大于 1KB 时会用到该项 large_client_header_buffers 4 128k; # 最大数量和最大客户端请求头的大小 ## # SSL Settings ## # 启用所有协议，禁用已废弃的不安全的SSL 2 和SSL 3 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE # 让服务器选择要使用的算法套件 ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; ## 访问日志 error_log /var/log/nginx/error.log; ## 错误日志 ## # Gzip Settings ## gzip on; gzip_disable \"msie6\"; text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; # 这个文件夹默认是空的 include /etc/nginx/sites-enabled/*; # 开启的 Server 服务配置&#125;### mail 模块## mail &#123; # See sample authentication script at: # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript # auth_http localhost/auth.php; # pop3_capabilities \"TOP\" \"USER\"; # imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; server &#123; listen localhost:110; protocol pop3; proxy on; &#125; server &#123; listen localhost:143; protocol imap; proxy on; &#125;&#125; 总结来说123456main：用于进行nginx全局信息的配置events：用于nginx工作模式的配置http：用于进行http协议信息的一些配置server：用于进行服务器访问信息的配置location：用于进行访问路由的配置upstream：用于进行负载均衡的配置 目前使用的一些nginx配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192# For more information on configuration, see:# * Official English Documentation: http://nginx.org/en/docs/# * Official Russian Documentation: http://nginx.org/ru/docs/#user nginx;worker_processes 2;error_log /var/log/nginx/error.log;pid /run/nginx.pid;#worker_rlimit_nofile 65535;# Load dynamic modules. See /usr/share/nginx/README.dynamic.#include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;http &#123; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. # include /etc/nginx/conf.d/*.conf; # 这段是只http的时候设置的 #*************************************************************************** #server &#123; #listen 80; #server_name localhost; # root /usr/share/nginx/html; # Load configuration files for the default server block. #include /etc/nginx/default.d/*.conf; #location / &#123; #proxy_pass http://localhost:8080; #proxy_set_header Host $host; #proxy_set_header X-Real-IP $remote_addr; #proxy_set_header X-Scheme $scheme; #proxy_pass_header Server; #proxy_redirect on; #&#125; #&#125; #*************************************************************************** # 这段是只https的时候设置的 #*************************************************************************** server &#123; listen 80; server_name XXX.XXXX.com; return 301 https://$server_name$request_uri; &#125; server &#123; listen 443; server_name XXX.XXXX.com; ssl on; ssl_certificate cert/XXX.XXXX.pem; ssl_certificate_key cert/XXX.XXXX.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location /&#123; proxy_pass http://localhost:8080; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; &#125; &#125; #****************************************************************************&#125;","tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Nginx http 强制跳转 https 地址","date":"2019-02-12T10:18:42.000Z","path":"2019/02/12/Nginx-http-强制跳转-https-地址/","text":"https 越来越普及，但是当用户自己访问 http 是控制不了的，所以强制跳转的功能就必不可少了，下面是几种强制跳转的方法 return 301返回 301 错误，并跳转到 https 地址12345server &#123; listen 80; server_name wxnacy.com; return 301 https://$server_name$request_uri;&#125; rewrite1rewrite ^(.*)$ https://$host$1 permanent; 两者相比，301 的方式在搜索引擎速度上要块一些。 error_page 4971error code 497: normal request was sent to HTTPS 在一个站点只允许 https 访问时, 如果使用 http 访问会报出497错误码1error_page 497 https://$host$uri?$args; index.html refresh百度页面 http://baidu.com 自动跳转 http://www.baidu.com 是灵活利用了 meta 的刷新属性12345&gt; $ curl http://baidu.com&lt;html&gt;&lt;meta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"&gt;&lt;/meta&gt;html&gt;","tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"nginx的基本使用","date":"2019-02-12T09:39:48.000Z","path":"2019/02/12/nginx的基本使用/","text":"Nginx是一款轻量级的网页服务器、反向代理服务器。相较于Apache、lighttpd具有占有内存少，稳定性高等优势。它最常的用途是提供反向代理服务。关于nginx的安装，网上有很多教程，大家都可以去百度上查找。这篇文章是来记录nginx的基本使用和配置中遇到的错误问题。 基本使用环境配置将命令脚本超链接到环境变量中1$ ln -sf /usr/local/nginx/sbin/nginx /usr/local/bin/nginx 启动1$ nginx 停止1$ nginx -s [start, stop] 重新启动1$ nginx -s reopen 修改 nginx.conf 后进行测试是否没有语法错误1$ nginx -t 然后重新加载配置，使之生效1$ nginx -s reload 系统命令的方式来启动停止1$ sudo systemctl [start, stop, restart] nginx 设置是否自动开机自启动1$ sudo systemctl [enable, disable] nginx 常见错误1、nginx: [error] invalid PID number “” in “/run/nginx.pid”nginx -s reload 报nginx: [error] invalid PID number &quot;&quot; in &quot;/run/nginx.pid&quot;错误遇到这个错误，需要先执行1$ nginx -c /etc/nginx/nginx.conf nginx.conf文件的路径可以从nginx -t的返回中找到。这时候如何没有报错，那么你就可以nginx -s reload如果还错误,请看第二个问题2、nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)错误详情12345nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] still could not bind() 错误描述：地址已被使用。可能nginx服务卡死了，导致端口占用。查看nginx的运行情况1$ ps aux | grep nginx 结果1234root 13332 0.0 0.0 56824 2796 ? Ss 17:00 0:00 nginx: master process nginx -c /etc/nginx/nginx.confnginx 13437 0.0 0.0 57360 3792 ? S 17:09 0:00 nginx: worker processnginx 13438 0.0 0.0 57228 3776 ? S 17:09 0:00 nginx: worker processroot 13854 0.0 0.0 112676 992 pts/0 S+ 18:09 0:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn nginx 使用kill指令删除进程1$ kill -9 13332 13437 13438 然后nginx -s reload刷新3、nginx绑定域名，发现使用域名访问不成功，用ip访问成功出现这种情况一般是因为你的服务器安全组没有设置相应的端口访问，比如http，需要设置80端口可以访问,https设置443端口。","tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"学习nginx遇到的一些问题","date":"2019-01-15T10:41:47.000Z","path":"2019/01/15/学习nginx遇到的一些问题/","text":"nginx 找不到安装地址今天看到了nginx,想到我在服务器里面安装了nginx，只是还没有用到，所以想看下其安装地址，却没有找到，后来谷歌下，发现用nginx -t就可以找到nginx.conf的文件位置，从而知道nginx的安装位置。123# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful","tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Python基础系列之*args和**kwargs的认识","date":"2019-01-06T14:46:05.000Z","path":"2019/01/06/Python基础系列之-args和-kwargs/","text":"*args和**kwargs这两个参数咱们经常用到，今天在巩固基础的时候，看到了这两个参数，做了一下对比，所以记录一下。 *args*args这种写法代表的是 元组，就比如我上面为啥说它们是参数，是因为他们经常在函数的参数中出现。下面咱们在例子中来说明1234567891011def getTupleParameter(x, *args): print('x is &#123;&#125;'.format(x)) print('args is &#123;&#125;'.format(args)) print('type is &#123;&#125;'.format(type(args))) for i in args: print('i is &#123;&#125;'.format(i))getTupleParameter(1, 2, 3, 4, 5, 6, 7)print('*'*100)getTupleParameter(1) 结果12345678910111213x is 1args is (2, 3, 4, 5, 6, 7)type is &lt;class 'tuple'&gt;i is 2i is 3i is 4i is 5i is 6i is 7********************************************************************x is 1args is ()type is &lt;class 'tuple'&gt; **kwargs*kwargs这种写法代表的是 字典，下面咱们在例子中来说明12345678910111213def getDictParameter(x, **kwargs): print('x is &#123;&#125;'.format(x)) print('kwargs is &#123;&#125;'.format(kwargs)) print('type is &#123;&#125;'.format(type(kwargs)))getDictParameter(1, a=1, b=2, c=3)getDictParameter(1)res = dict( a=1, b=2, c=3)getDictParameter(1, **res) 结果123456789x is 1kwargs is &#123;'b': 2, 'a': 1, 'c': 3&#125;type is &lt;class 'dict'&gt;x is 1kwargs is &#123;&#125;type is &lt;class 'dict'&gt;x is 1kwargs is &#123;'b': 2, 'a': 1, 'c': 3&#125;type is &lt;class 'dict'&gt; *args和**kwargs的混合使用*args和**kwargs在程序中一起使用很常见12345def getTupleAndDict(x, *args, **kwargs): print('x is &#123;&#125;'.format(x)) print('kwargs is &#123;&#125;'.format(kwargs)) print('args is &#123;&#125;'.format(args))getTupleAndDict(1, 2, 3, 4, 5, A=1, B=2, C=3, D=4) 结果123x is 1kwargs is &#123;'D': 4, 'C': 3, 'A': 1, 'B': 2&#125;args is (2, 3, 4, 5)","tags":[]},{"title":"Linux find命令的使用","date":"2018-12-29T07:58:44.000Z","path":"2018/12/29/Linux-find命令的使用/","text":"find命令是根据文件的属性进行查找，如文件名，文件大小，所有者，所属组，是否为空，访问时间，修改时间等。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。 语法 find 地址 参数 参数1234567891011121314151617181920find 根据下列规则判断 path 和 expression，在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。如果 path 是空字串则使用目前路径，如果 expression 是空字串则使用 -print 为预设 expression。expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。-mount, -xdev : 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件-amin n : 在过去 n 分钟内被读取过-anewer file : 比文件 file 更晚被读取过的文件-atime n : 在过去n天内被读取过的文件-cmin n : 在过去 n 分钟内被修改过-cnewer file :比文件 file 更新的文件-ctime n : 在过去n天内被修改过的文件-empty : 空的文件-gid n or -group name : gid 是 n 或是 group 名称是 name-ipath p, -path p : 路径名称符合 p 的文件，ipath 会忽略大小写-name name, -iname name : 文件名称符合 name 的文件。iname 会忽略大小写-size n : 文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数，k 表示 kilo bytes，w 是二个位元组。-type c : 文件类型是 c 的文件。d: 目录c: 字型装置文件b: 区块装置文件p: 具名贮列f: 一般文件l: 符号连结s: socket 实例查找当前目录及其子目录下的名字为Podfile的文件1find . -name Podfile 查找etc目录下名字为所有延伸档名是 .c 的文件列出来1find /etc -name '*.c' 查找在系统中最后10分钟访问的文件1find / -amin -10 将目前目录及其子目录下所有最近 20 天内更新过的文件列出1find . -ctime -20 查找/var/log目录中更改时间在7日以前的普通文件，并在删除之前询问它们1find /var/log -type f -mtime +7 -ok rm &#123;&#125; \\; 查找前目录中文件属主具有读、写权限，并且文件所属组的用户和其他用户具有读权限的文件1find . -type f -perm 644 -exec ls -l &#123;&#125; \\; 为了查找系统中所有文件长度为0的普通文件，并列出它们的完整路径1find / -type f -size 0 -exec ls -l &#123;&#125; \\; 其他的例子12345678910111213141516find / -amin -10 # 查找在系统中最后10分钟访问的文件(access time)find / -atime -2 # 查找在系统中最后48小时访问的文件find / -empty # 查找在系统中为空的文件或者文件夹find / -group cat # 查找在系统中属于 group为cat的文件find / -mmin -5 # 查找在系统中最后5分钟里修改过的文件(modify time)find / -mtime -1 #查找在系统中最后24小时里修改过的文件find / -user fred #查找在系统中属于fred这个用户的文件find / -size +10000c #查找出大于10000000字节的文件(c:字节，w:双字，k:KB，M:MB，G:GB)find / -size -1000k #查找出小于1000KB的文件3.使用混合查找方式查找文件 参数有： ！，-and(-a)，-or(-o)。find /tmp -size +10000c -and -mtime +2 #在/tmp目录下查找大于10000字节并在最后2分钟内修改的文件find / -user fred -or -user george #在/目录下查找用户是fred或者george的文件文件find /tmp ! -user panda #在/tmp目录中查找所有不属于panda用户的文件","tags":[]},{"title":"2018的总结","date":"2018-12-29T07:58:18.000Z","path":"2018/12/29/杂谈/","text":"2018年很快进入了尾声，想想今年不在想过碌碌无为的事情，开始有了自己的规划。一方面可能是因为有了压力，另一方面感觉自己需要更多的成长。2018年定的任务完成度完成了70%，自己感觉完成的不好。需要更多的激励，更多的鞭策。在最后的2018年的几天了，想着自己2019年的规划，落实到实际过程中，不在庸庸碌碌，用这边文章来写下自己的心路历程。只写自己的成长方面 拓展书籍读至少12本书，也就是一个月一本书 风闻有你 耶路撒冷三千年 加尔文要义 专业书籍随着工作，发现自己需要学习的越来越多，所以今年至少需要看的书籍。PS:以后再补充 跟着老齐学python(持之以恒，有始有终) 数据结构 python核心编程 算法 圣经怎么都不能没有自己的信仰，圣经也是需要读一遍","tags":[]},{"title":"Supervisor管理进程","date":"2018-12-26T07:27:04.000Z","path":"2018/12/26/Supervisor管理进程/","text":"Supervisor 是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用 Supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。 安装Supervisor 可以运行在 Linux、Mac OS X 上。如前所述，Supervisor 是 Python 编写的，所以安装起来也很方便，可以直接用 pip 安装:1$ sudo pip install supervisor 因为supervisor，只能安装在python2.X上面，目前开发用的是3.5.0，所以这里用到了pyenv。pyenv来管理用python2.X还是python3.X。学习pyenv请点链接：pyenv 配置 Supervisor 相当强大，提供了很丰富的功能，不过我们可能只需要用到其中一小部分。安装完成之后，可以编写配置文件，来满足自己的需求。为了方便，我们把配置分成两部分 Supervisor（Supervisor 是一个 C/S 模型的程序，这是 server 端，对应的有 client 端：supervisorctl）和应用程序（即我们要管理的程序） 首先来看 Supervisor 的配置文件。安装完 Supervisor 之后，可以运行 echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件里：1echo_supervisord_conf &gt; /etc/supervisord.conf 去除里面大部分注释和“不相关”的部分，我们可以先看这些配置：12345678910111213141516171819202122232425262728[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码[supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files = relative/directory/*.ini ; 可以是 *.conf 或 *.ini 我们把上面这部分配置保存到 /etc/supervisord.conf（或其他任意有权限访问的文件）然后启动 supervisord（通过 -c 选项指定配置文件路径，如果不指定会按照这个顺序查找配置文件：$CWD/supervisord.conf, $CWD/etc/supervisord.conf, /etc/supervisord.conf）1supervisord -c /etc/supervisord.conf 查看 supervisord 是否在运行：1ps aux | grep supervisord program 配置上面我们已经把 supervisrod 运行起来了，现在可以添加我们要管理的进程的配置文件。可以把所有配置项都写到 supervisord.conf 文件里，但并不推荐这样做，而是通过 include 的方式把不同的程序（组）写到不同的配置文件里。为了举例，我们新建一个目录 /etc/supervisor/ 用于存放这些配置文件，相应的，把 /etc/supervisord.conf 里 include 部分的的配置修改一下：12[include]files = /etc/supervisor/*.conf 假设有个用 Python 和 Flask 框架编写的用户中心系统，取名 usercenter，用 gunicorn 做 web 服务器。项目代码位于 /home/leon/projects/usercenter，gunicorn 配置文件为 gunicorn.py，WSGI callable 是 wsgi.py 里的 app 属性。所以直接在命令行启动的，方式可能是这样的：12cd /home/leon/projects/usercentergunicorn -c gunicorn.py wsgi:app 现在编写一份配置文件来管理这个进程（需要注意：用 supervisord 管理时，gunicorn 的 daemon 选项需要设置为 False）：123456789101112131415[program:usercenter]directory = /home/leon/projects/usercenter ; 程序的启动目录command = gunicorn -c gunicorn.py wsgi:app ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = leon ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /data/logs/usercenter_stdout.log; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 一份配置文件至少需要一个 [program:x] 部分的配置，来告诉 supervisord 需要管理那个进程。[program:x] 语法中的 x 表示 program name，会在客户端（supervisorctl 或 web 界面）显示，在 supervisorctl 中通过这个值来对程序进行 start、restart、stop 等操作","tags":[{"name":"Supervisor","slug":"Supervisor","permalink":"http://yoursite.com/tags/Supervisor/"}]},{"title":"python数组的相关知识","date":"2018-12-25T02:43:28.000Z","path":"2018/12/25/python数组交集、并集、差集/","text":"数组是在python中很常见，所以关于数组的知识点也相当重要。这篇博客是把工作中用到的知识点记录一下，持续更新中 1、数组的交集、并集、差集2、数组转字符串，字符串转数组 数组的交集、并集、差集123456a = [1, 3, 65, 2, 7]b = [3, 2, 5, 4]print(set(a).intersection(set(b))) # 交集print(set(a).union(set(b))) # 并集print(set(a).difference(set(b))) # 差集，在a中但不在b中的元素print(set(b).difference(set(a))) # 差集，在b中但不在a中的元素 结果1234&#123;2, 3&#125;&#123;65, 1, 2, 3, 4, 5, 7&#125;&#123;65, 1, 7&#125;&#123;4, 5&#125; 数组转字符串，字符串转数组字符串转数组123str = '1,2,3'arr = str.split(',')print(\"arr is &#123;&#125;\".format(arr)) 结果1arr is ['1', '2', '3'] 数组转字符串12345678# 方法1arr = ['a','b']str1 = ','.join(arr)print('str1 is &#123;&#125;'.format(str1))#方法2arr = [1,2,3]str2 = ','.join(str(i) for i in arr)print('str2 is &#123;&#125;'.format(str2)) 结果12str1 is a,bstr2 is 1,2,3","tags":[]},{"title":"Flask-OAuth urlparse错误","date":"2018-12-13T07:52:27.000Z","path":"2018/12/13/Flask-OAuth-urlparse错误/","text":"最近用到了Flash-OAuth的三方库，一运行，错误12345 File \"/Users/FQY/Desktop/bm_blog/blog/extensions.py\", line 10, in &lt;module&gt; from flask_oauth import OAuth File \"/Users/FQY/env350/lib/python3.5/site-packages/flask_oauth.py\", line 13, in &lt;module&gt; from urlparse import parseImportError: No module named 'urlparse' 先说明下我用的python环境是3.5.0,百度下说是from urlparse import urljoin 是2.0的python用法，3.0的python用法已经urlparse已经被重新设置,所以进入三方库里面改下就可以了。进入flask_oauth.py文件中进行修改原代码1234567import httplib2from functools import wrapsfrom urlparse import urljoinfrom flask import request, session, json, redirect, Responsefrom werkzeug import url_decode, url_encode, url_quote, \\ parse_options_header, Headersimport oauth2 修改以后的代码1234567import httplib2from functools import wrapsfrom urllib.parse import urljoinfrom flask import request, session, json, redirect, Responsefrom werkzeug import url_decode, url_encode, url_quote, \\ parse_options_header, Headersimport oauth2 这时候在运行就可以了。","tags":[]},{"title":"Linux tree:目录结构以树形显示","date":"2018-12-12T06:51:20.000Z","path":"2018/12/12/目录结构以树形显示/","text":"有时候看到别人的目录结构是以树形显示，看到以后感觉很酷，所以自己就google了下，发现了很简单。 实例123456789101112131415╭─FQY@bogon ~/Desktop/hello╰─$ tree .├── dong.txt├── dong_s.txt -&gt; dong.txt├── hell│ ├── hell│ │ └── hello│ └── hello├── hello├── hello1├── hello_s -&gt; hello└── tmd.rtf2 directories, 8 files 具体更多的关于tree的指令，后期在补充 未完接续。。。。。。。。。。","tags":[]},{"title":"Linux file命令:查看文件信息或类型","date":"2018-12-11T08:32:25.000Z","path":"2018/12/11/Linux-file命令-查看文件信息或类型/","text":"Linux file命令用于辨识文件类型,通过file指令，我们得以辨识该文件的类型。 语法 file [-bcLvz][-f &lt;名称文件&gt;][-m &lt;魔法数字文件&gt;…][文件或目录…]参数 -b 列出辨识结果时，不显示文件名称。 -c 详细显示指令执行过程，便于排错或分析程序执行的情形。 -f&lt;名称文件&gt; 指定名称文件，其内容有一个或多个文件名称时，让file依序辨识这些文件，格式为每列一个文件名称。 -L 直接显示符号连接所指向的文件的类别。 -m&lt;魔法数字文件&gt; 指定魔法数字文件。 -v 显示版本信息。 -z 尝试去解读压缩文件的内容 (支持gzip类型)。 [文件或目录…]要确定类型的文件列表，多个文件之间使用空格分开，可以使用shell通配符匹配多个文件 实例查看文件类型12[root@hardwareupdate linux_test]# file hello.txthello.txt: UTF-8 Unicode text 使用不带任何选项的 file 命令，即可查看指定文件的类型信息。在上面的例子中可以看出 poetry.txt 的文件类型为 text，编码格式为 UTF-8。 使用-b就只显示编码和文件类型，不显示文件名12[root@hardwareupdate linux_test]# file -b hello.txtUTF-8 Unicode text 使用-i，咱们能看出什么?12[root@hardwareupdate linux_test]# file -i hello.txthello.txt: text/plain; charset=utf-8 常见的文件类型： text/plain：普通文本。 text/html：HTML文本。 application/pdf：PDF文档。 application/msword：Word文档。 image/png：PNG图片。 mage/jpeg：JPEG图片。 application/x-tar：TAR文件。 application/x-gzip：GZIP文件 按照清单去工作如果我们需要用 file 命令查看大量文件的类型信息，恰好这些文件的名称都被存储在了一个文本文件中，那么-f选项就派上用场了。我们可以通过-f选项来指定这个文本文件，file 命令就会乖乖地去逐个查看每一个文件的类型信息，示例如下:1234567891011#文件中含有三个待查文件, 我们故意设置了一个不存在的文件, 位于最后一个[roc@roclinux ~]$ cat poetry_list.txt/root/book/poetry.txt/root/book/poetry_s.txtNothing.txt #使用-f选项执行file命令[roc@roclinux ~]$ file -f poetry_list.txt/root/book/poetry.txt: ASCII text/root/book/poetry_s.txt: symbolic link to `poetry.txt'Nothing.txt: ERROR: cannot open `Nothing.txt ' (No such file or directory) 其他的各种指令，大家也可以去尝试，比如-L，当用软链接的时候不会直接返回文件类型，而是返回的是symbolic link to XXX，所以加-L就可以知道它是哪个类型了。 参考file命令_Linux file命令：查看文件信息或类型","tags":[]},{"title":"常见的HTTP状态码(HTTP Status Code)","date":"2018-12-11T03:29:43.000Z","path":"2018/12/11/常见的HTTP状态码-HTTP-Status-Code/","text":"2开头 （请求成功）表示成功处理了请求的状态代码。200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。201 （已创建） 请求成功并且服务器创建了新的资源。202 （已接受） 服务器已接受请求，但尚未处理。203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。204 （无内容） 服务器成功处理了请求，但没有返回任何内容。205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。206 （部分内容） 服务器成功处理了部分 GET 请求,流视频直播一般返回206 3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。400 （错误请求） 服务器不理解请求的语法。401 （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。403 （禁止） 服务器拒绝请求。404 （未找到） 服务器找不到请求的网页。405 （方法禁用） 禁用请求中指定的方法。406 （不接受） 无法使用请求的内容特性响应请求的网页。407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。408 （请求超时） 服务器等候请求时发生超时。409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。415 （不支持的媒体类型） 请求的格式不受请求页面的支持。416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。417 （未满足期望值） 服务器未满足”期望”请求标头字段的要求。 5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。 500 （服务器内部错误） 服务器遇到错误，无法完成请求。501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。503 （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。","tags":[]},{"title":"Linux文件管理之cmp、diff的使用详解","date":"2018-12-10T03:41:40.000Z","path":"2018/12/10/Linux文件管理之cmp、diff的使用详解/","text":"cmp和diff都是用于比较两个文件的差异。但是两者的不同之处在于: cmp用于比较两个二进制文件，而diff主要用于比较两个文本文件 cmpLinux cmp命令用于比较两个文件是否有差异。当相互比较的两个文件完全一样时，则该指令不会显示任何信息。若发现有所差异，预设会标示出第一个不同之处的字符和列数编号。若不指定任何文件名称或是所给予的文件名为”-“，则cmp指令会从标准输入设备读取数据。 语法 cmp [参数][文件1][文件2] 参数 -c或–print-chars 除了标明差异处的十进制字码之外，一并显示该字符所对应字符。 -i&lt;字符数目&gt;或–ignore-initial=&lt;字符数目&gt; 指定一个数目。 -l或–verbose 标示出所有不一样的地方。 -s或–quiet或–silent 不显示错误信息。 -v或–version 显示版本信息。 –help 在线帮助。实例12345678910111213141516╭─FQY@bogon ~/Desktop/hello╰─$ cmp hello hello1 # hello1是从hello复制的，然后在hello1添加了一些内容╭─FQY@bogon ~/Desktop/hello╰─$ cmp hello hello1 # 出现EOF 是则 hello1 的第一部分与 hello 相同，但在 hello1 中还有其他数据cmp: EOF on hello╭─FQY@bogon ~/Desktop/hello╰─$ cmp -l hello hello1 # 这时候在hello中添加一些数据，在重新比较37 351 14138 230 16339 277 14440 346 14641 226 141cmp: EOF on hello ╭─FQY@bogon ~/Desktop/hello╰─$ cmp hello hello1 1 ↵hello hello1 differ: char 37, line 4 diffLinux diff命令用于比较文件的差异。diff以逐行的方式，比较文本文件的异同处。如果指定要比较目录，则diff会比较目录中相同文件名的文件，但不会比较其中子目录 语法 diff[参数][文件1或目录1][文件2或目录2] 参数 -B或–ignore-blank-lines 不检查空白行。 -c 显示全部内文，并标出不同之处。 -C&lt;行数&gt;或–context&lt;行数&gt; 与执行”-c-&lt;行数&gt;”指令相同。 -d或–minimal 使用不同的演算法，以较小的单位来做比较。 -D&lt;巨集名称&gt;或ifdef&lt;巨集名称&gt; 此参数的输出格式可用于前置处理器巨集。 -e或–ed 此参数的输出格式可用于ed的script文件。 -f或-forward-ed 输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。 -H或–speed-large-files 比较大文件时，可加快速度。 -l&lt;字符或字符串&gt;或–ignore-matching-lines&lt;字符或字符串&gt; 若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。 -i或–ignore-case 不检查大小写的不同。 -l或–paginate 将结果交由pr程序来分页。 -n或–rcs 将比较结果以RCS的格式来显示。 -N或–new-file 在比较目录时，若文件A仅出现在某个目录中，预设会显示： Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。 -P或–unidirectional-new-file 与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。 -q或–brief 仅显示有无差异，不显示详细的信息。 -r或–recursive 比较子目录中的文件。 -s或–report-identical-files 若没有发现任何差异，仍然显示信息。 -S&lt;文件&gt;或–starting-file&lt;文件&gt; 在比较目录时，从指定的文件开始比较。 -t或–expand-tabs 在输出时，将tab字符展开。 -T或–initial-tab 在每行前面加上tab字符以便对齐。 -u,-U&lt;列数&gt;或–unified=&lt;列数&gt; 以合并的方式来显示文件内容的不同。 -v或–version 显示版本信息。 -w或–ignore-all-space 忽略全部的空格字符。 -W&lt;宽度&gt;或–width&lt;宽度&gt; 在使用-y参数时，指定栏宽。 -x&lt;文件名或目录&gt;或–exclude&lt;文件名或目录&gt; 不比较选项中所指定的文件或目录。 -X&lt;文件&gt;或–exclude-from&lt;文件&gt; 您可以将文件或目录类型存成文本文件，然后在=&lt;文件&gt;中指定此文本文件。 -y或–side-by-side 以并列的方式显示文件的异同之处。 –help 显示帮助。 –left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。 –suppress-common-lines 在使用-y参数时，仅显示不同之处。 实例12345678910111213141516╭─FQY@bogon ~/Desktop/hello╰─$ diff hello hello1 1 ↵4c4,5&lt; python好用\\ No newline at end of file---&gt; node很方便&gt; 加油\\ No newline at end of file ╭─FQY@bogon ~/Desktop/hello╰─$ diff hello hello1 -y -W 50 2 ↵生活很美好 生活很美好现实很骨感 现实很骨感理想很丰富 理想很丰富python好用 \\ node很方便 &gt; 加油% 说明“|”表示前后2个文件内容有不同“&lt;”表示后面文件比前面文件少了1行内容“&gt;”表示后面文件比前面文件多了1行内容","tags":[]},{"title":"Linux cksum的使用详解","date":"2018-12-10T02:38:22.000Z","path":"2018/12/10/Linux-cksum的使用详解/","text":"cksum命令是检查文件的CRC是否正确，确保文件从一个系统传输到另一个系统的过程中不被损坏。这种方法要求校验和在源系统中被计算出来，在目的系统中又被计算一次，两个数字进行比较，如果校验和相等，则该文件被认为是正确传输了。注意：CRC是指一种排错检查方法，即循环冗余校验法。指定文件交由cksum命令进行校验后，会返回校验结果供用户核对文件是否正确无误。若不指定任何文件名称或是所给予的文件名为”-“，则cksum命令会从标准输入设备中读取数据。 语法 cksum [–help][–version][文件…] 参数 –help：在线帮助。 –version：显示版本信息。 文件…:需要进行检查的文件路径 实例12345678╭─FQY@bogon ~/Desktop/hello╰─$ cksum hello # 命令执行后，将输出校验码等相关的信息4294967295 0 hello╭─FQY@bogon ~/Desktop/hello╰─$ vim hello # 因为hello文件是空的，所以字节数为0，这时候给hello里面添加数据并保存╭─FQY@bogon ~/Desktop/hello╰─$ cksum hello # 再一次执行命令，这时候看到字节数是36。\"4090568956\"表示校验码4090568956 36 hello 注意：如果文件中有任何字符被修改，都将改变计算后CRC校验码的值。","tags":[]},{"title":"Linux 系统目录结构","date":"2018-12-07T07:52:20.000Z","path":"2018/12/07/Linux-系统目录结构/","text":"登录系统后，在当前命令窗口下输入命令：123[root@hardwareupdate ~]# lsgit log mysqlbkup.sh pip-9.0.1 Python-3.4.1 s3fs-fuse anaconda-ks.cfg get-pip.py install.log.syslog mewe.bak1 nohup.out pip-9.0.1-py2.py3-none-any.whl Python-3.6.2 [root@hardwareupdate ~]# 树状目录结构 以下是对这些目录的解释： /bin：bin是Binary的缩写, 这个目录存放着最经常使用的命令。 /boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ：dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc：这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home：用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib：这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media：linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt：这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 /root：该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /selinux：这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv：该目录存放一些服务启动之后需要提取的数据。 /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。 sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。 当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。 /tmp：这个目录是用来存放一些临时文件的。 /usr：这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。 /usr/bin：系统用户使用的应用程序。 /usr/sbin：超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src：内核源代码默认的放置目录。 /var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 /run：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。 在 Linux 系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。/etc：上边也提到了，这个是系统中的配置文件，如果你更改了该目录下的某个文件可能会导致系统不能启动。/bin, /sbin, /usr/bin, /usr/sbin: 这是系统预设的执行文件的放置目录，比如 ls 就是在/bin/ls 目录下的。值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用户），而/sbin, /usr/sbin 则是给root使用的指令。 /var： 这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在/var/log 目录下，另外mail的预设放置也是在这里","tags":[]},{"title":"Linux 修改文件权限命令chmod、chgrp、chown详解","date":"2018-12-07T03:39:55.000Z","path":"2018/12/07/修改文件权限命令chmod、chgrp、chown详解/","text":"Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。文件或目录的访问权限分为只读，只写和可执行三种。以文件为例，只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。有三种不同类型的用户可对文件或目录进行访问：文件所有者，同组用户、其他用户。所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。 chmodchmod命令是非常重要的，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。 语法 chmod [-cfvR] [–help] [–version] mode file… 参数说明mode : 权限设定字串，格式如下 : [ugoa…][[+-=][rwxX]…][,…] 其中 u 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。 +表示增加权限、- 表示取消权限、= 表示唯一设定权限。 r 表示可读取，w 表示可写入，x 表示可执行，X表示只有当该文件是个子目录或者该文件已经被设定过为可执行。 r(Read，读取，权限值为4)：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目 录的权限 w(Write,写入，权限值为2)：对文件而言，具有新增、修改文件内容的权限；对目录来说，具有删除、移动目录内文件的权限。 x(eXecute，执行，权限值为1)：对文件而言，具有执行文件的权限；对目录了来说该用户具有进入目录的权限。 其他参数说明： -c : 若该文件权限确实已经更改，才显示其更改动作 -f : 若该文件权限无法被更改也不要显示错误讯息 -v : 显示权限变更的详细资料 -R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更) –help : 显示辅助说明 –version : 显示版本 实例在桌面创建一个hello的文件夹，里面有一个hello的文件。12345678╭─FQY@bogon ~/Desktop╰─$ ll | grep hello drwxr-xr-x 3 FQY staff 96B 12 7 11:55 hello╭─FQY@bogon ~/Desktop╰─$ cd hello╭─FQY@bogon ~/Desktop/hello╰─$ ll | grep hello-rw-r--r-- 1 FQY staff 0B 12 7 11:55 hello 咱们首先看hello文件夹，是drwxr-xr-x, d表示是文件夹,如果不是文件夹，则第一个是-。咱们上面说到有3种用户类型:文件所有者，同组用户、其他用户.rwx表示文件所有者的权限，r-x表示同组用户的权限,r-x表示其他用户。 根据上面所说的那样，r为4，w为2，x为1，所以rwx就是7，r-x表示5，所以当咱们需要让同组和其他用户都可以对hello.rtf有读写的权利,12345╭─FQY@bogon ~/Desktop/hello╰─$ chmod 766 hello╭─FQY@bogon ~/Desktop/hello╰─$ ll | grep hello-rwxrw-rw- 1 FQY staff 0B 12 7 11:55 hello 下面来举些例子熟悉下: 权限 数值 -rwxrw-r–- 764 -rw-r–-r–- 644 -rw-rw-r–- 664 创建一个file1.text文件，将文件 file1.txt 设为所有人皆可读取: chmod ugo+r file1.txt 将文件 file1.txt 设为所有人皆可读取 : chmod a+r file1.txt 将文件 file1.txt 与 file2.txt 设为该文件拥有者，与其所属同一个群体者可写入，但其他以外的人则不可写入 : chmod ug+w,o-w file1.txt file2.txt 所以咱们晓得:chmod ug=rwx,o=x file 和 chmod 771 file，效果是一样的。 chgrp Linux chgrp命令用于变更文件或目录的所属群组。 语法 chgrp [选项] [组] [文件] 参数说明: -c或–changes 效果类似”-v”参数，但仅回报更改的部分。 -f或–quiet或–silent 不显示错误信息。 -h或–no-dereference 只对符号连接的文件作修改，而不更动其他任何相关文件。 -R或–recursive 递归处理，将指定目录下的所有文件及子目录一并处理。 -v或–verbose 显示指令执行过程。 –help 在线帮助。 –reference=&lt;参考文件或目录&gt; 把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同。 –version 显示版本信息。 实例将log2012.log文件由root群组改为bin群组 123456[root@localhost test]# ll---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chgrp -v bin log2012.log“log2012.log” 的所属组已更改为 bin[root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log 根据指定文件改变文件的群组属性 改变文件log2013.log的群组属性，使得文件log2013.log的群组属性和参考文件log2012.log的群组属性相同 1234567[root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log[root@localhost test]# chgrp --reference=log2012.log log2013.log [root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log chown使用权限: root 使用方式 : chown [-cfhvR] [–help] [–version] user[:group] file… 说明 : Linux/Unix 是多人多工作业系统，所有的档案皆有拥有者。利用 chown 可以将档案的拥有者加以改变。一般来说，这个指令只有是由系统管理者(root)所使用，一般使用者没有权限可以改变别人的档案拥有者，也没有权限可以自己的档案拥有者改设为别人。只有系统管理者(root)才有这样的权限。 参数user : 新的档案拥有者的使用者 ID group : 新的档案拥有者的使用者群体(group) -c或-change：作用与-v相似，但只传回修改的部分 -f或–quiet或–silent：不显示错误信息 -h或–no-dereference：只对符号链接的文件做修改，而不更改其他任何相关文件 -R或-recursive：递归处理，将指定目录下的所有文件及子目录一并处理 -v或–verbose：显示指令执行过程 –dereference：作用和-h刚好相反 –help：显示在线说明 –reference=&lt;参考文件或目录&gt;：把指定文件或目录的所有者与所属组，统统设置成和参考文件或目录的所有者与所属组相同 –version：显示版本信息 实例将文件 file1.txt 的拥有者设为 users 群体的使用者 runoob : chown runoob:users file1.txt 将目前目录下的所有文件与子目录的拥有者皆设为 users 群体的使用者 lamport : chown -R lamport:users * chmod和chown的区别 chmod与chown看似拼写还有点差不多，但是两者的用途是不同的。chmod是用来设置文件夹和文件权限的，比如我们在VPS主机中文件不可读写，需要用来设置777权限；而chown是用来设置用户组的，比如授权某用户组，方便控制用户权限。 chown 修改文件和文件夹的用户和用户组属性1。要修改文件hh.c的所有者.修改为sakia的这个用户所有 chown sakia hh.c 这样就把hh.c的用户访问权限应用到sakia作为所有者 2。将目录 /tmp/sco 这个目录的所有者和组改为sakia和组net chown -R sakia:net /tmp/sco chmod 修改文件和文件夹读写执行属性 1。把hh.c文件修改为可写可读可执行 chmod 777 hh.c 要修改某目录下所有的文件属性为可写可读可执行 chmod 777 . 把文件夹名称与后缀名用*来代替就可以了。 同理若是要修改所有htm文件的属性 chmod 777 *.htm","tags":[]},{"title":"Linux下chattr命令详解","date":"2018-12-05T09:04:13.000Z","path":"2018/12/05/linux下chattr、chgrp命令详解/","text":"chattr 可以修改文件属性 有时候你发现用root权限都不能修改某个文件，大部分原因是曾经用chattr命令锁定该文件了。chattr命令的作用很大，通过chattr命令修改属性能够提高系统的安全性，但是它并不适合所有的目录。chattr命令不能保护/、/dev、/tmp、/var目录。lsattr命令是显示chattr命令设置的文件属性 lsattrlsattr命令是显示chattr命令设置的文件属性 chattr和chmod的区别这两个命令是用来查看和改变文件、目录属性的，与chmod这个命令相比，chmod只是改变文件的读写、执行权限，更底层的属性控制是由chattr来改变的。 语法 chattr [-RV][-v&lt;版本编号&gt;][+/-/=&lt;属性&gt;][文件或目录…] 属性 + ：在原有参数设定基础上，追加参数。 - ：在原有参数设定基础上，移除参数。 = ：更新为指定参数设定。 A：文件或目录的 atime (access time)不可被修改(modified), 可以有效预防例如手提电脑磁盘I/O错误的发生。 S：硬盘I/O同步选项，功能类似sync。 a：即append，设定该参数后，只能向文件中添加数据，而不能删除，多用于服务器日志文件安全，对于日志系统很好用，这个权限让目标文件只能追加，不能删除，而且不能通过编辑器追加。 c：即compresse，设定文件是否经压缩后再存储。读取时需要经过自动解压操作。 d：即no dump，设定文件不能成为dump程序的备份目标。 i：设定文件不能被删除、改名、设定链接关系，同时不能写入或新增内容。i参数对于文件 系统的安全设置有很大帮助。 j：即journal，设定此参数使得当通过mount参数：data=ordered 或者 data=writeback 挂 载的文件系统，文件在写入时会先被记录(在journal中)。如果filesystem被设定参数为 data=journal，则该参数自动失效。 s：保密性地删除文件或目录，即硬盘空间被全部收回。 u：与s相反，当设定为u时，数据内容其实还存在磁盘中，可以用于undeletion。 各参数选项中常用到的是a和i。a选项强制只可添加不可删除，多用于日志系统的安全设定。而i是更为严格的安全设定，只有superuser (root) 或具有CAP_LINUX_IMMUTABLE处理能力（标识）的进程能够施加该选项 参数-R 递归处理，将指定目录下的所有文件及子目录一并处理。 -v&lt;版本编号&gt; 设置文件或目录版本。 -V 显示指令执行过程。 +&lt;属性&gt; 开启文件或目录的该项属性。 -&lt;属性&gt; 关闭文件或目录的该项属性。 =&lt;属性&gt; 指定文件或目录的该项属性 实例1234567891011121314151617181920212223╭─root@iz ~╰─# ls hello.conf # 我在下面创建一个hello.conf文件╭─root@iz~╰─# chattr -V +i hello.conf # 设定文件不能被删除、改名等chattr 1.42.9 (28-Dec-2013)hello.conf的标志被设为 ----i--------e--╭─root@iz ~╰─# rm hello.confrm: 无法删除\"hello.conf\": 不允许的操作╭─root@iz ~╰─# lsattr hello.conf # 用lsattr 可以查看chattr下面的设置----i--------e-- hello.conf╭─root@iz ~╰─# lsattr hello.conf----i--------e-- hello.conf╭─root@iz ~╰─# chattr -V -i hello.confchattr 1.42.9 (28-Dec-2013)hello.conf的标志被设为 -------------e--这时候在删除就可以删除了╭─root@iz ~╰─# rm hello.conf","tags":[]},{"title":"python 批量上传文件到阿里云oss，并写入Excel，存到本地","date":"2018-11-29T05:59:03.000Z","path":"2018/11/29/python-批量上传文件到阿里云oss/","text":"最近公司要往阿里云oss上传视频，大小差不多有200G，原先让运营去一个一个的添加，但是这能麻烦死人，所以就让技术去批量上传。所以研究了一下用python往oss上传视频 首先需引用以下几个模块123pip install oss2pip install tablibpip install pyexcel-xlsx 其次因为本地的视频都是比如中文.mp4这样的，所以引入一个随机字符串123456789101112import randomdef generate_random_str(randomlength=8): \"\"\" 生成一个指定长度的随机字符串 \"\"\" random_str = '' base_str = 'ABCDEFGHIGKLMNOPQRSTUVWXYZabcdefghigklmnopqrstuvwxyz0123456789' length = len(base_str) - 1 for i in range(randomlength): random_str += base_str[random.randint(0, length)] return random_str 因为是文件夹里面套文件夹，但是只上传文件，所以需要获取子文件夹下面的视频代码如下：123456789def upload(dir): fs = os.listdir(dir) for f in fs: file = dir + \"/\" + f if os.path.isdir(file): upload(file) else: if 'DS_Store' not in file and 'png' not in f and 'JPG' not in f: putAliyun(file, f) 备注：因为文件夹里面还有图片，所以去除后缀为png、JPG的图片。因为用的是mac上传，所以文件夹里面有.DS_Store，所以也需要去除 所以这个的整个代码如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#!/usr/bin/env python# ! -*- coding:utf-8 -*-import oss2import randomimport osimport tablibimport timeossDir = '/Users/FQY/Desktop/upload'key = XXXsecret = XXXbucketname = XXXdataset = tablib.Dataset()header = ('title', 'url')dataset.headers = headerdef generate_random_str(randomlength=8): \"\"\" 生成一个指定长度的随机字符串 \"\"\" random_str = '' base_str = 'ABCDEFGHIGKLMNOPQRSTUVWXYZabcdefghigklmnopqrstuvwxyz0123456789' length = len(base_str) - 1 for i in range(randomlength): random_str += base_str[random.randint(0, length)] return random_strdef getmkname(path): remoteName = path.replace(ossDir, '') dir_names = remoteName.split('/') dir_names.pop() res = filter(None, dir_names) mkdir_name = '-'.join(res) return mkdir_name#获得上传的时长def progress_callback(bytes_consumed, total_bytes): print('bytes_consumed is &#123;&#125;'.format(bytes_consumed)) print('total_bytes is &#123;&#125;'.format(total_bytes))def putAliyun(path, f): key = 'language/' + str(int(time.time())) + generate_random_str() + '.mp4' auth = oss2.Auth(key, secret) bucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com', bucketname) result = bucket.put_object_from_file(key=key, filename=path,progress_callback=progress_callback) if result.status == 200: aliyun = 'http://mewevideo.oss-cn-hangzhou.aliyuncs.com/&#123;&#125;'.format(key) title = '【&#123;&#125;】&#123;&#125;'.format(getmkname(path), f.split('.mp4')[0]) dataset.append([title, aliyun]) else: print('upload fail,error code', result.status)def upload(dir): fs = os.listdir(dir) for f in fs: file = dir + \"/\" + f if os.path.isdir(file): upload(file) else: if 'DS_Store' not in file and 'png' not in f and 'JPG' not in f: putAliyun(file, f)upload(ossDir)myfile = open('/Users/FQY/Desktop/mydata_video.xlsx', 'wb')myfile.write(dataset.xlsx)myfile.close() tablib的介绍，可以观看以下的文章利用tablib、make_response 进行文件的下载","tags":[]},{"title":"sudo -s 切换到root账户","date":"2018-11-20T09:50:31.000Z","path":"2018/11/20/sudo-s-切换到root账户/","text":"sudo su 和 sudo -s都是切换到root用户，不同的是： sudo su 环境用的是目标用户(root)的环境sudo -s 环境用的是当前用户本身的环境","tags":[]},{"title":"ubuntu系统下gitlab的创建","date":"2018-11-20T08:37:22.000Z","path":"2018/11/20/ubuntu系统下gitlab的创建/","text":"摘要： gitlab的介绍、环境、创建步骤、关键点、卸载gitlab gitlab的介绍 GitLab 是一个用于仓库管理系统的开源项目，使用Git作为代码管理工具，并在此基础上搭建起来的web服务。 环境 ubuntu 18.04LTS 创建步骤gitlab官网上面有在ubuntu创建gitlab的步骤https://about.gitlab.com/install/ 可以点击按照步骤来做 关键点每次修改配置的时候记得sudo gitlab-ctl reconfigure，使配置生效 指令12345678910111213141516查看运行状态 sudo gitlab-ctl status启动所有 gitlab 组件 sudo gitlab-ctl start 停止所有 gitlab 组件 sudo gitlab-ctl stop 重启所有 gitlab 组件 sudo gitlab-ctl restart 启动服务 sudo gitlab-ctl reconfigure 修改默认的配置文件 sudo vim /etc/gitlab/gitlab.rb 检查gitlab gitlab-rake gitlab:check SANITIZE=true --trace 查看日志 sudo gitlab-ctl tail 初始账户和密码有的笔记上说的默认账户和密码是下面的 账户：root密码：5iveL!fe 但是我打开网页的时候，直接提示的是 change your password。这时候我做的就是把密码修改下，密码最少8个字，当你修改过了以后你就可以登录了。比如： 账户：root密码：xxkh1234 卸载1、停止gitlab1sudo gitlab-ctl stop 2、卸载gitlab（注意这里写的是gitlab-ce）1sudo dpkg -r gitlab-ce 3、查看gitlab进程1ps aux | grep gitlab 4、杀掉第一个进程（就是带有好多………….的进程）1kill -9 18777 杀掉后，在ps aux | grep gitlab确认一遍，还有没有gitlab的进程 5、删除所有包含gitlab文件1find / -name gitlab | xargs rm -rf","tags":[]},{"title":"Linux grep、tail命令的混合使用","date":"2018-11-14T06:06:29.000Z","path":"2018/11/14/Linux-grep、tail命令的使用/","text":"grepLinux grep命令用于查找文件里符合条件的字符串。grep指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设grep指令会把含有范本样式的那一列显示出来。若不指定任何文件名称，或是所给予的文件名为”-“，则grep指令会从标准输入设备读取数据。 语法 grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][–help][范本样式][文件或目录…] 或 grep [选项] “模式” [文件] 参数 -a 或 –text : 不要忽略二进制的数据。 -A&lt;显示行数&gt; 或 –after-context=&lt;显示行数&gt; : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b 或 –byte-offset : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; 或 –before-context=&lt;显示行数&gt; : 除了显示符合样式的那一行之外，并显示该行之前的内容。 -c 或 –count : 计算符合样式的列数。 -C&lt;显示行数&gt; 或 –context=&lt;显示行数&gt;或-&lt;显示行数&gt; : 除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; 或 –directories=&lt;动作&gt; : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; 或 –regexp=&lt;范本样式&gt; : 指定字符串做为查找文件内容的样式。 -E 或 –extended-regexp : 将样式为延伸的普通表示法来使用。 -f&lt;规则文件&gt; 或 –file=&lt;规则文件&gt; : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F 或 –fixed-regexp : 将样式视为固定字符串的列表。 -G 或 –basic-regexp : 将样式视为普通的表示法来使用。 -h 或 –no-filename : 在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H 或 –with-filename : 在显示符合样式的那一行之前，表示该行所属的文件名称。 -i 或 –ignore-case : 忽略字符大小写的差别。 -l 或 –file-with-matches : 列出文件内容符合指定的样式的文件名称。 -L 或 –files-without-match : 列出文件内容不符合指定的样式的文件名称。 -n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。 -q 或 –quiet或–silent : 不显示任何信息。 -r 或 –recursive : 此参数的效果和指定”-d recurse”参数相同。 -s 或 –no-messages : 不显示错误信息。 -v 或 –revert-match : 显示不包含匹配文本的所有行。 -V 或 –version : 显示版本信息。 -w 或 –word-regexp : 只显示全字符合的列。 -x –line-regexp : 只显示全列符合的列。 -y : 此参数的效果和指定”-i”参数相同 实例12345678910[root@hard supervisord]# grep 'POST.*play_order.*return 200' tmd.log[2018-10-21 14:39:21,190] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-21 14:42:03,327] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-21 14:43:27,720] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-21 18:15:25,090] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-21 18:33:20,517] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-22 16:20:55,863] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-22 17:41:36,183] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-22 17:52:44,021] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200[2018-10-22 17:55:15,172] [base.py:451 ] [DEBUG] [POST /adminapi/v3/play_order ] return 200 grep &#39;POST.*play_order.*return 200&#39; tmd.log 这个等同于grep &#39;play_order&#39; tmd.log | grep &#39;POST&#39; | grep &#39;return 200&#39; 12345[root@hard supervisord]# grep -c 'POST.*play_order.*return 200' tmd.log62[root@hard supervisord]# grep -c 'play_order' tmd.log | grep 'POST' | grep 'return 200'[root@hard supervisord]# grep 'play_order' tmd.log | grep 'POST' | grep -c 'return 200'62 grep可以和很多的命令一起使用1234查看Linux 某些程序进程 ps aux [root@iZ2ze3269b etc]# ps aux | grep mysqlroot 2371 0.0 0.0 112676 980 pts/0 S+ 14:34 0:00 grep --color=auto mysqlmysql 10810 0.1 9.4 1599384 367788 ? Sl 10月11 13:13 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid tailtail 命令可用于查看文件的内容，有一个常用的参数 -f 常用于查阅正在改变的日志文件。tail -f filename 会把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，只要 filename 更新就可以看到最新的文件内容。 语法 tail [参数] [文件] 参数 -f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c&lt;数目&gt; 显示的字节数 -n&lt;行数&gt; 显示行数 –pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, –quiet, –silent 从不输出给出文件名的首部 -s, –sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 实例 要显示 notes.log 文件的最后 10 行，请输入以下命令： tail notes.log 要跟踪名为 notes.log 的文件的增长情况，请输入以下命令： tail -f notes.log 此命令显示 notes.log 文件的最后 10 行。当将某些行添加至 notes.log 文件时，tail 命令会继续显示这些行。 显示一直继续，直到您按下（Ctrl-C）组合键停止显示。显示文件 notes.log 的内容，从第 20 行至文件末尾: tail +20 notes.log 混合使用有时候我们会查询正在改变的文件，但是我们只想查看其中的某一些信息，这时候就可以使用tail、grep的混合使用 tail -f filename | grep ‘DEBUG’ 实例 tail -f tmd.log | grep ‘DEBUG.template.begin’","tags":[]},{"title":"vim 指令","date":"2018-11-14T02:24:25.000Z","path":"2018/11/14/vim-指令/","text":"上下左右h, j, k , l四个键分别代表方向键← ↓ ↑ → ，也就是上下左右，每次只能向上、向左、向右、向下一下。如果向下移动5行的话，可以用数字+快捷键5j,那么向右移动5个就是5l。 翻页组合键 1234&lt;ctrl&gt; + f 向下移动一页 &lt;ctrl&gt; + d 向下移动半页&lt;ctrl&gt; + b 向上移动一页&lt;ctrl&gt; + u 向上移动半页 行首行尾1230 #快速跳到行首$ #快速调到行尾g_ #快速跳到行尾最后一个非空字符 页头页尾12gg #快速跳到第一行G #快速跳到最后一行 行内查找1234fx #从当前光标开始向右查找字符 x，x 为目标字符nfx #从当前广告开始向右查找第 n 个字符 x，n 为数字Fx #从当前光标开始向左查找字符 x，x 为目标字符nfx #从当前广告开始向左查找第 n 个字符 x，n 为数字 全文查找如果你想要把全文的 native 都找到，可以按下 / 进入 command 模式，随后输入 native 然后回车，此时光标会定位在第一个目标上，并高亮所有找到的目标单词。此时按下 n 光标就会向下在高亮的单词上依次跳转，N 则会反方向跳转。 1234/word \" 输入 / 会进入 command 模式，再输入先要搜索的单词并回车进行搜索?word \" / 是向光标以后搜索，? 是向前搜索n \" 英文字母 n，根据 / 或 ? 搜索的方向定位到下一个匹配目标N \" 与 n 相反，定位匹配目标 复制、粘贴、删除复制当前行 yy，删除并复制当前行 dd，粘贴到光标下一行 p 12345678910111213dd \" 删除当前行ndd \" 向下删除 n 行d1G / dgg \" 删除第一行到当前行的数据dG \" 删除当前行到最后一行的数据d$ \" 删除当前字符到行尾d0 \" 从行首删除到当前字符yy \" 复制当前行nyy \" 从当前行开始复制 n 行y1G / ygg \" 从第一行复制到当前行yG \" 从当前行复制到最后一行y0 \" 从行首复制到当前字符y$ \" 从当前字符复制到行尾p, P \" 黏贴，p 黏贴到光标下一行，P 黏贴到光标上一行 1234x \" 向后删除一个字符nx \" 向后删除 n 个字符X \" 向前删除一个字符nX \" 向前删除 n 个字符 撤销和重做12u \" 撤销&lt;c-r&gt; \" 重做","tags":[]},{"title":"Linux cp、ln命令的使用","date":"2018-11-13T10:17:07.000Z","path":"2018/11/13/Linux-cp、ln命令的使用/","text":"cpcp命令主要用于复制文件或目录 语法1cp [options] source dest 实例复制文件 cp 源文件 目标文件 1234567FQY@bogon ~/Desktop/edc╰─$ cp /Users/FQY/Desktop/1.xlsx 1.xlsx╭─FQY@bogon ~/Desktop/edc╰─$ lltotal 72-rw-------@ 1 FQY staff 28K 11 13 15:14 1.xlsx-rw-r--r-- 1 FQY staff 0B 11 13 14:31 bm.conf 复制目录下面的所有文件使用指令”cp”将当前目录”test/“下的所有文件复制到新目录”newtest”下，输入如下命令 $ cp –r test/ newtest 参数说明： -a：此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合。 -d：复制时保留链接。这里所说的链接相当于Windows系统中的快捷方式。 -f：覆盖已经存在的目标文件而不给出提示。 -i：与-f选项相反，在覆盖目标文件之前给出提示，要求用户确认是否覆盖，回答”y”时目标文件将被覆盖。 -p：除复制文件的内容外，还把修改时间和访问权限也复制到新文件中。 -r：若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。 -l：不复制文件，只是生成链接文件。 lnLinux ln命令是一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接。当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。 语法 ln [参数][源文件或目录][目标文件或目录] 软链接 1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 2.软链接可以 跨文件系统 ，硬链接不可以 3.软链接可以对一个不存在的文件名进行链接 4.软链接可以对目录进行链接 硬链接 1.硬链接，以文件副本的形式存在。但不占用实际空间。 2.不允许给目录创建硬链接 3.硬链接只有在同一个文件系统中才能创建 必要参数 -b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 实例创建硬链接 ln destop/1.xlsx 1.xlsx 创建软链接 ln -s destop/1.xlsx 1.xlsx","tags":[]},{"title":"git clone 子模块","date":"2018-11-09T07:20:04.000Z","path":"2018/11/09/git-clone-子模块/","text":"最近在做博客的时候，用到了其他的themes，因为配置，所以需要修改themes里面的代码，这时候有两种做法，一种是直接把代码下到本地，然后将代码直接拷贝项目中，另一种是用git做管理，项目中添加子项目。我先做的是先fork该theme一份，然后git我fork下来的这个项目。具体做法如下 添加子项目git submodule add [address]1234567$ git submodule add https://github.com/chaconinc/DbConnectorCloning into 'DbConnector'...remote: Counting objects: 11, done.remote: Compressing objects: 100% (10/10), done.remote: Total 11 (delta 0), reused 11 (delta 0)Unpacking objects: 100% (11/11), done.Checking connectivity... done. 默认情况下，子模块会将子项目放到一个与仓库同名的目录中，本例中是 “DbConnector”。 如果你想要放到其他地方，那么可以在命令结尾添加一个不同的路径。 自动初始化并更新仓库中的每一个子模块123456789101112131415$ git clone --recursive https://github.com/chaconinc/MainProjectCloning into 'MainProject'...remote: Counting objects: 14, done.remote: Compressing objects: 100% (13/13), done.remote: Total 14 (delta 1), reused 13 (delta 0)Unpacking objects: 100% (14/14), done.Checking connectivity... done.Submodule 'DbConnector' (https://github.com/chaconinc/DbConnector) registered for path 'DbConnector'Cloning into 'DbConnector'...remote: Counting objects: 11, done.remote: Compressing objects: 100% (10/10), done.remote: Total 11 (delta 0), reused 11 (delta 0)Unpacking objects: 100% (11/11), done.Checking connectivity... done.Submodule path 'DbConnector': checked out 'c3f01dc8862123d317dd46284b05b6892c7b29bc' 在包含子模块的项目上工作如果我们在主项目中提交并推送但并不推送子模块上的改动，其他尝试检出我们修改的人会遇到麻烦，因为他们无法得到依赖的子模块改动。 那些改动只存在于我们本地的拷贝中。为了确保这不会发生，你可以让 Git 在推送到主项目前检查所有子模块是否已推送。 git push 命令接受可以设置为 “check” 或 “on-demand” 的 –recurse-submodules 参数。 如果任何提交的子模块改动没有推送那么 “check” 选项会直接使 push 操作失败。1234567891011121314$ git push --recurse-submodules=checkThe following submodule paths contain changes that cannot be found on any remote: DbConnectorPlease try git push --recurse-submodules=on-demandor cd to the path and use git pushto push them to a remote. 如你所见，它也给我们了一些有用的建议，指导接下来该如何做。 最简单的选项是进入每一个子模块中然后手动推送到远程仓库，确保它们能被外部访问到，之后再次尝试这次推送。 另一个选项是使用 “on-demand” 值，它会尝试为你这样做。12345678910111213141516$ git push --recurse-submodules=on-demandPushing submodule 'DbConnector'Counting objects: 9, done.Delta compression using up to 8 threads.Compressing objects: 100% (8/8), done.Writing objects: 100% (9/9), 917 bytes | 0 bytes/s, done.Total 9 (delta 3), reused 0 (delta 0)To https://github.com/chaconinc/DbConnector c75e92a..82d2ad3 stable -&gt; stableCounting objects: 2, done.Delta compression using up to 8 threads.Compressing objects: 100% (2/2), done.Writing objects: 100% (2/2), 266 bytes | 0 bytes/s, done.Total 2 (delta 1), reused 0 (delta 0)To https://github.com/chaconinc/MainProject 3d6d338..9a377d1 master -&gt; master 如你所见，Git 进入到 DbConnector 模块中然后在推送主项目前推送了它 参考git clone 子模块（module）git子模块","tags":[]},{"title":"ssh 免密码登录","date":"2018-11-08T06:56:06.000Z","path":"2018/11/08/ssh 免密码登录/","text":"通常的ssh登录有两种方式，一种是通过密码登录，一种是通过密钥登录，在实际使用过程中，会发现用密码登录很繁琐，需要每次都输入密码，这时候用密钥登录就会很方便。 密码登录格式12$ ssh root@10.2.8.41root@10.2.8.41's password: 这时候输入密码就可以登录成功1234$ ssh root@10.2.8.41root@10.2.8.41's password:Last login: Thu Nov 1 11:34:05 2018 from 10.2.0.33[root@hardwareupdate ~]# 密钥登录创建密钥12345678910[root@host ~]$ ssh-keygen -t rsa &lt;== 建立密钥对Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): &lt;== 按 EnterCreated directory '/root/.ssh'.Enter passphrase (empty for no passphrase): &lt;== 输入密钥锁码，或直接按 Enter 留空Enter same passphrase again: &lt;== 再输入一遍密钥锁码Your identification has been saved in /root/.ssh/id_rsa. &lt;== 私钥Your public key has been saved in /root/.ssh/id_rsa.pub. &lt;== 公钥The key fingerprint is:0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:df:9b:cc:08 root@host 密钥生成以后，在.ssh下面会多两个文件，id_rsa.pub是公钥，id_rsa是私钥123[root@host ~]$ cd ~/.ssh[root@host .ssh]$ lsid_rsa id_rsa.pub known_hosts config 然后把公钥上传到服务器上，scp等同于ssh-copy-id -i123[root@A ~]# scp /root/.ssh/id_rsa.pub root@192.168.1.181:/root/.ssh/authorized_keys root@192.168.1.181's password:id_rsa.pub 100% 223 0.2KB/s 00:00 由于还没有免密码登录的，所以要输入一次服务器的密码登录,如果服务器没有authorized_keys文件，用touch authorized_keys 创建 服务器登录服务器，进入.ssh里面，给authorized_keys设置权限1234[root@host ~]$ cd ~/.ssh[root@host .ssh]$ lsauthorized_keys known_hosts[root@host .ssh]$ chmod 600 authorized_keys 本地配置权限12[root@host ~]$ cd ~/.ssh[root@host .ssh]$ chmod 600 id_rsa 这时候就可以用密钥登录了1ssh -i ~/.ssh/id_rsa root@192.168.100.39 用config去管理用ssh -i ~/.ssh/id_rsa root@192.168.100.39登录时很繁琐的，这时候就可以用config去管理 例如123456789101112# ~/.ssh/config 文件示例# Host 参数标明以下内容仅适用于访问 236 主机时适用，Host 参数本身只是一个入口字符串；Host fuwuqi HostName 192.168.99.236 User git Port 22 IdentityFile ~/.ssh/rsa-michael-236Host github HostName 192.168.99.3 User root Port 22 IdentityFile ~/.ssh/rsa-3root-michael 配置完这些以后，就可以用这个登录了123[root@host ~] ssh fuwuqiLast login: Thu Nov 8 09:40:00 2018 from 192.168.99.236Welcome to Alibaba Cloud Elastic Compute Service !","tags":[]},{"title":"centos7 安装zsh和oh-my-zsh","date":"2018-11-06T08:53:06.000Z","path":"2018/11/06/centos7-安装zsh和oh-my-zsh/","text":"目前的centos系统默认的shell还是bash，但是zsh被称为终极shell，国外有个程序员开发出了一个能够让你快速上手的zsh项目，叫做「oh my zsh」，Github 网址是：https://github.com/robbyrussell/oh-my-zsh 有了这玩意zsh用起来直接就变成神器了。 查看系统当前的shell1echo $SHELL 返回的结果是:1/bin/bash 查看bin下是否有zsh包12345678910cat /etc/shells**********************************************返回的结果是:/bin/sh/bin/bash/sbin/nologin/usr/bin/sh/usr/bin/bash/usr/sbin/nologinPS.默认没有安装zsh zsh安装1sudo yum install -y zsh 然后在输入cat /etc/shells查看 1234567/bin/sh/bin/bash/sbin/nologin/usr/bin/sh/usr/bin/bash/usr/sbin/nologin/bin/zsh 配置将zsh设置成默认的shell 1chsh -s /bin/zsh 设置完以后不会立即生效，需要重启方能生效，所以我们可以配置完oh-my-zsh以后再重启 oh-my-zsh安装1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 如果出现以下界面表示成功 12345678910111213__ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \\/ __ \\ / __ `__ \\/ / / / /_ / / ___/ __ \\ / /_/ / / / / / / / / / / /_/ / / /_(__ ) / / / \\____/_/ /_/ /_/ /_/ /_/\\__, / /___/____/_/ /_/ /____/ ....is now installed!Please look over the ~/.zshrc file to select plugins, themes, and options.p.s. Follow us at https://twitter.com/ohmyzsh.p.p.s. Get stickers and t-shirts at http://shop.planetargon.com. 配置主题主题链接地址 oh-my-zsh主题 目前我使用的主题是bira 修改主题 1$ vim ~/.zshrc 刚安装oh-my-zsh默认的主题是robbyrussell，将ZSH_THEME改成bira 更新配置 1$ source ~/.zshrc 然后重启, 使zsh配置生效 1$ reboot","tags":[]},{"title":"对Python装饰器的一些理解","date":"2018-10-31T10:13:52.000Z","path":"2018/10/31/对Python装饰器的一些理解/","text":"1.装饰器的定义装饰器是对在运行期间对函数进行一些外部功能的扩展。也就是在其他函数不需要做任何代码变动的前提下增加额外功能。 2.装饰器的应用场景插入日志、性能测试、事务处理、缓存、权限校验等场景 例如我们在接收请求的时候多会看是否包含某一个元素。比如查看是否包含有code,如果有code，就打印错误并且ruturn返回 1234567891011121314151617def requestedCode(*params): def _wrapper(func): def wrappered(*args, **kwargs): print('%s is running' % func.__name__) for code in params: print('错误错误') return return func(*args, *kwargs) return wrappered return _wrapper @requestedCode('code')def hello_world(): print('i am world') print(hello_world()) 3.装饰器使用 @functools.wraps 的理由Python 中使用装饰器对在运行期对函数进行一些外部功能的扩展。但是在使用过程中，由于装饰器的加入导致解释器认为函数本身发生了改变，在某些情况下——比如测试时——会导致一些问题。Python 通过 functool.wraps 为我们解决了这个问题：在编写装饰器时，在实现前加入 @functools.wraps(func) 可以保证装饰器不会对被装饰函数造成影响。比如，在 Flask 中，我们要自己重写 login_required 装饰器，但不想影响被装饰器装饰的方法，则 login_required 装饰器本身可以写成下面的样子： 1234567891011def login_required_(func): @wraps(func) def decorated_view(*args, **kwargs): if current_app.login_manager._login_disabled: return func(*args, **kwargs) elif not current_user.is_authenticated: # return current_app.login_manager.unauthorized() return redirect(url_for(\"login.loginPage\", next=request.url)) return func(*args, **kwargs) return decorated_view 参考如何理解Python装饰器？Python 中实现装饰器时使用 @functools.wraps 的理由","tags":[]},{"title":"Python基础学习----切片、迭代、列表生成式","date":"2018-10-31T10:13:32.000Z","path":"2018/10/31/Python基础学习-切片、迭代、列表生成式/","text":"切片通常我们取list里面的元素会这样写12345list = ['zhangsan','lisi','wangwu']list[0] list[1] list[2]取n个的话：for i in range(3): list[i] 但是这样用循环很麻烦，可以这样做 12list[0:3] #这样取的是从0开始，往后数3个数list[1:3] #这样取的是从1开始，往后数2个数 迭代 如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代。在Python中，迭代是通过for … in来完成的 在Python不是都是迭代的，所以有时候需要判断是否可以迭代 1234567&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance('abc', Iterable) # str是否可迭代True&gt;&gt;&gt; isinstance([1,2,3], Iterable) # list是否可迭代True&gt;&gt;&gt; isinstance(123, Iterable) # 整数是否可迭代False 列表生成式列表生成式是Python中内置的非常简单却非常强大的可以用来创建list的生成式。例如要生成list [1,2,3,4,5,6,7,8,9],可以用list(range(1,10))但如果要生成[1x1, 2x2, 3x3, …, 10x10]怎么做？方法一是循环： 123456&gt;&gt;&gt; L = []&gt;&gt;&gt; for x in range(1, 11):... L.append(x * x)...&gt;&gt;&gt; L[1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 方法二：列表生成式 123[x * x for x in range(1,10)]得出：[1, 4, 9, 16, 25, 36, 49, 64, 81] 列表生成式还有其他的用法*在for循环后面加if判断语句例如：仅偶数的平方 12[x * x for x in range(1,11) if x % 2 == 0 ][4, 16, 36, 64, 100] *使用两层循环,生成全排列 12[m + n for m in 'ABC' for n in 'XYZ']['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] 举例判断是否可以迭代，在用列表生成式 12345L = ['Hello', 'World', 18, 'Apple', None][x for x in L if isinstance(x,str) == True]结果：['Hello', 'World', 'Apple'] 注：文章是在廖雪峰大大的网站学习后写下的学习摘要。","tags":[]},{"title":"Flask 上下文全局变量","date":"2018-10-31T10:13:21.000Z","path":"2018/10/31/Flask-上下文全局变量/","text":"变量名 上下文 说明 current_app 程序上下文 当前激活程序的程序实例 g 程序上下文 处理请求时用作临时存储的对象，每次请求都会重设这个变量 request 请求上下文 请求对象，封装了客户端发出的HTTP请求中的内容 session 请求上下文 用户会话，用于存储请求之间需要记住的值的词典 Flask 在分发请求之前激活(或推送)程序和请求上下文，请求处理完成后再将其删除。程 序上下文被推送后，就可以在线程中使用 current_app 和 g 变量。类似地，请求上下文被 推送后，就可以使用 request 和 session 变量。如果使用这些变量时我们没有激活程序上 下文或请求上下文，就会导致错误。","tags":[]},{"title":"flask下 gunicorn在Python中的使用","date":"2018-10-31T10:13:09.000Z","path":"2018/10/31/flask下-gunicorn在Python中的使用/","text":"gunicorn使用非常简单，并且也非常好用，所以需要写一下自己的理解。😀 使用gunicorn的使用，需先安装flask,安装方法如下： 1pip install flask 下面为一个简单的用flask写的web服务,main.py 12345678from flask import Flaskapp = Flask(__name__)@app.route('/')def index(): return 'hello world'if __name__ == '__main__': app.debug = True app.run() gunicorn的作用就是用命令行来启动服务器。安装如下： 1pip install gunicorn 最简单的启动命令为：1gunicorn main:app 其中code就是指main.py.app就是那个wsgifunc的名字。 这样运行的话， gunicorn 默认作为一个监听 127.0.0.1:8000 的web server，可以在本机通过： http://127.0.0.1:8000 访问。如果要通过网络访问，则需要绑定不同的地址（也可以同时设置监听端口），设置0.0.0.0可以监听到所有ip的请求：1gunicorn -b 0.0.0.0:8080 main:app 在多核服务器上，为了支持更多的并发访问并充分利用资源，可以使用更多的 gunicorn 进程：1gunicorn -w 4 main:app 两者结合到一起就是：1gunicorn -w 4 -b 0.0.0.0:8080 main:app 备注： -b 表示 gunicorn 开发的访问地址 -w 表示开启多少个线程","tags":[]},{"title":"Python之random的send()的使用","date":"2018-10-31T10:12:55.000Z","path":"2018/10/31/Python之random的send-的使用/","text":"对于send方法的定义，在一篇文章中看到这样一个定义，发现很符合这个解释seed( ) 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed( )值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同 情况下面的几行代码 12345678910import randomrandom.seed(5)print (\"random 5 is \", random.random())random.seed(10)print (\"random 10 is \", random.random())random.seed(7)print (\"random 7 is \", random.random())random.seed(5)print(\"random 5 is \", random.random()) 运行结果为: 1234random 5 is 0.6229016948897019random 10 is 0.5714025946899135random 7 is 0.32383276483316237random 5 is 0.6229016948897019 你会发现当seed()值是一样的时候，输出的结果是一样的。而不一样的值得出的结果不一样。","tags":[]},{"title":"python之random的random的使用","date":"2018-10-31T10:12:33.000Z","path":"2018/10/31/python之random的random的使用/","text":"random.random()生成0和1之间的随机浮点数float例如： 1print (\"random 7 is \", random.random()) 运行结果为：1random 7 is 0.32383276483316237","tags":[]},{"title":"利用tablib、make_response 进行文件的下载","date":"2018-10-31T10:12:23.000Z","path":"2018/10/31/利用tablib、make-response-进行文件的下载/","text":"tablib 主要作用是将数据导出为各种不同的格式，包括excel，json，html，yaml，csv，tsv等格式。使用起来也非常简单。 tablib的下载1pip install tablib 下面就是文件下载的代码123456789101112131415161718192021222324252627282930import tablibfrom flask import make_responsedef file_download(): dataset1 = tablib.Dataset() header1 = ('ID', 'Name', 'Tel', 'Age') dataset1.headers = header1 dataset1.append([1, 'zhangsands', 13711111111, 16]) dataset1.append([2, 'lisiasfasd阿斯顿发gwus', 13911111111, 20]) dataset1.append([4, 'zhao发送到li2u', 15811111111, 25]) header2 = ('ID', 'Name', 'Tel', 'Age') data2 = [ [1, 'zhangsan', 13711111111, 16], [2, 'lisi', 13811111111, 18], [3, 'wangwu', 13911111111, 20], [4, 'zhaoliu', 15811111111, 25] ] dataset2 = tablib.Dataset(*data2, headers=header2) dataset1.title = 'dataset1' # 设置Excel中表单的名称 dataset2.title = 'dataset2' # 如果有多个sheet表单，使用DataBook就可以了 myDataBook = tablib.Databook((dataset1, dataset2)) ds = myDataBook.export('xlsx') response = make_response(ds) response.headers['Content-Disposition'] = 'attachment; filename=&#123;&#125;'.format('dhel.xlsx') return response 引用：Python tablib模块tablib文档","tags":[]},{"title":"pip 升级所遇到的问题","date":"2018-10-31T10:12:11.000Z","path":"2018/10/31/pip-升级所遇到的问题/","text":"pip的原有版本是9.0.1，最近发现pip可以升级了，想到pip升级到10以上用了下面各种方法，都不管用,如下：用了mac/limux方法 :123 pip install -U pip easy_install --upgrade pippip install --upgrade pip 用了windows 方法：12python -m pip install --upgrade pippython -m pip install -U pip 最后从源头做起，里面搞定1curl https://bootstrap.pypa.io/get-pip.py | python3","tags":[]},{"title":"pip安装时ReadTimeoutError解决办法","date":"2018-10-31T10:12:00.000Z","path":"2018/10/31/pip安装时ReadTimeoutError解决办法/","text":"有一个本地服务器，网速很慢，下载老是出错，出现12pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. 经过google，发现用下面的内容就可以完美解决1pip --default-timeout=100 install gevent","tags":[]},{"title":"安装PyCrypto以后出现的错误","date":"2018-10-31T10:11:50.000Z","path":"2018/10/31/安装PyCrypto以后出现的错误/","text":"最近另一个同事安装了PyCrypto，并且在本地和服务器运行都没有错误。当我download下来的时候，安装PyCrypto，运行竟然出现了错误。如下：123456789101112131415homeassistant | 16-07-01 18:35:24 ERROR (MainThread) [homeassistant.bootstrap] Error during setup of component winkhomeassistant | Traceback (most recent call last):homeassistant | File \"/usr/src/app/homeassistant/bootstrap.py\", line 150, in _setup_componenthomeassistant | if not component.setup(hass, config):homeassistant | File \"/usr/src/app/homeassistant/components/wink.py\", line 29, in setuphomeassistant | from pubnub import Pubnubhomeassistant | File \"/usr/local/lib/python3.4/site-packages/pubnub.py\", line 25, in &lt;module&gt;homeassistant | from Crypto.Cipher import AEShomeassistant | File \"/usr/local/lib/python3.4/site-packages/Crypto/Cipher/__init__.py\", line 78, in &lt;module&gt;homeassistant | from Crypto.Cipher._mode_ecb import _create_ecb_cipherhomeassistant | File \"/usr/local/lib/python3.4/site-packages/Crypto/Cipher/_mode_ecb.py\", line 29, in &lt;module&gt;homeassistant | from Crypto.Util._raw_api import (load_pycryptodome_raw_lib,homeassistant | File \"/usr/local/lib/python3.4/site-packages/Crypto/Util/_raw_api.py\", line 33, in &lt;module&gt;homeassistant | from Crypto.Util.py3compat import byte_stringhomeassistant | ImportError: cannot import name 'byte_string' 解决办法是123pip3 uninstall pycryptopip3 uninstall pycryptodomepip3 install pycryptodome 这时候就可以正常运行了","tags":[]},{"title":"使用tablib出现的错误","date":"2018-10-31T10:11:39.000Z","path":"2018/10/31/使用tablib出现的错误/","text":"最近公司要发邮件，基于tablib的强大功能，我理所当然的使用了它。但是在使用过程中发现一个bug，具体bug报这个错误1Using a coordinate with ws.cell is deprecated. Use ws[coordinate] instead\" 刚开始是报警告，后面因为换电脑直接更新requerement.txt，然后发邮件就直接报错123DeprecationWarning: Call to deprecated function remove_sheet (Use wb.remove(worksheet) or del wb[sheetname]). wb.remove_sheet(sheet) 后来经过查资料发现是因为tablib里面使用openpyxl的问题。openpyxl的版本过高，导致的问题，把openpyxl的版本改下就OK了。12原来的openpyxl版本是2.5.4.将其降到2.5.0以下就没问题了。pip install openpyxl==2.4.9","tags":[]},{"title":"flask-excel 下载的时候出现OSError错误","date":"2018-10-31T10:11:27.000Z","path":"2018/10/31/flask-excel-下载的时候出现OSError错误/","text":"最近在使用flask-excel报OSError: No content, file name. Nothing is given错误1return excel.make_response_from_records(items, \"xlsx\", file_name=\"all_content\") 经过查考是因为需要添加支持xlsx的控件1pip install pyexcel-xlsx 这时候就会完美解决","tags":[]},{"title":"iOS开发杂记","date":"2018-10-31T10:10:26.000Z","path":"2018/10/31/iOS开发杂记/","text":"因为记性不好，常常看到点东西，都感觉很好，但是经常时间一长都忘了，所以现在些杂记，记住这些。慢慢补充。 1.iOS屏幕旋转iOS屏幕旋转可以用系统通知判断方向UIDeviceOrientationDidChangeNotification; 是在屏幕旋转过以后UIApplicationWillChangeStatusBarOrientationNotification;屏幕没有旋转过的时候调用，可以用系统通知 12[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(autorotateDirection)name:UIDeviceOrientationDidChangeNotification object:nil]; 2.tableView头部偏离问题最近在用tableView的时候，出现自动偏移了64PX，经过查资料，发现需要设置下 12345if([selfrespondsToSelector:@selector(edgesForExtendedLayout)])&#123; self.edgesForExtendedLayout= UIRectEdgeNone;&#125;[self.navigationController.navigationBar setTranslucent:YES]","tags":[]},{"title":"关于cocoapods管理库遇到的坑","date":"2018-10-31T10:10:15.000Z","path":"2018/10/31/关于cocoapods管理库遇到的坑/","text":"今天花了一点时间来做cocoapods管理自己写的库问题。发现遇到好多坑。 记得这样放 记得当你pod lib lint XXKH.podspec成功的时候，记得给库加入tag值123git tag '1.0.0'git push --tagspod spec lint 然后是检查下，最后提交给pod，具体为pod trunk push XXKH.podspec","tags":[]},{"title":"git Authentication failed 错误","date":"2018-10-31T10:08:47.000Z","path":"2018/10/31/git-Authentication-failed-错误/","text":"最近在windows上面安装git的以后，git某一个项目，出现输入账号密码的界面，这时候应当输入你的用户名和密码。用户名是你的登录账号，密码是你的密码。这时候如果输入错误。那么你就git clone git… 会出现Authentication failed错误。这时候你无论修改 12git config --global user.name 'name'git config --global user.email 'email' 会发现还是报这个错误。然后我把git删除了，重装也还是不成。后来经大神指点，发现一个非常简单的解决方法。 123456 (一)进入控制面板（二）选择用户账户（三）选择管理你的凭据（四）选择Windows凭据（五）选择git保存的用户信息（六）选择编辑或者进行删除操作 这时候你在git clone git…，你就会发现成功了。 123git add .git commit -m 'good'git push origin master","tags":[]},{"title":"Git tag值的使用","date":"2018-10-31T10:07:55.000Z","path":"2018/10/31/Git-tag值的使用/","text":"项目中因为业务的需要，需要打标签。所以这里就把常用的几个命令写下来，方便以后自己在打tag的时候可以直接用到。 查看标签12git tag #这会看到项目下包含的标签git show v1.1.0 #查看该标签下的版本信息 打标签打标签有两种，轻量标签和附注标签,轻量标签是指向提交对象的引用，附注标签则是仓库中的一个独立对象. 12git tag v1.1.0 #创建轻量标签git tag -a v1.1.0 -m \"1.1.0版本\" #创建附注标签 创建附注Tag时，参数a即annotated的缩写，指定Tag类型，后附Tag名。参数m指定Tag说明，说明信息会保存在Tag对象中。 切换标签1git checkout v1.1.0 删除标签删除本地标签1git tag -d v1.1.0 #删除tag 删除远程标签 123git push origin :refs/tags/标签名 git push origin :refs/tags/protobuf-2.5.0rc1 tag推送到项目管理仓库注意：打tag的时候先把代码提交到项目管理仓库，然后在提交tag,所以在提交tag值的时候可以先git push origin master 12git push origin v1.1.0 #将v1.1.0 Tag提交到git服务器git push origin –-tags # 将本地所有Tag一次性提交到git服务器","tags":[]},{"title":"git的初始用","date":"2018-10-31T10:07:44.000Z","path":"2018/10/31/git的初始用/","text":"git配置全局的用户名和邮箱 12git config --global user.name xxkhgit config --global user.email xxx@gmail.com 查看用户名和邮箱12git config user.namegit config user.email 记住密码在服务器上 clone 代码第一次通常会提示输入密码，为了下次不再提示，可以在 clone 后做如下操作1git config credential.helper store 初始化项目12345678cd project_root # 进入项目目录git init # 初始化git仓库git add . # 添加文件到仓库git commit -m 'init commit' # 提交代码到本地仓库git remote add origin $&#123;repository_path&#125; # 将项目关联到git servergit pull origin master # 同步代码git push origin master # push代码到远程仓库git clone $&#123;repository_path&#125; # 新的位置clone项目 重新提交提交后如果发现遗漏可以使用 git commit –amend 重新提交123git commit -m 'initial commit'git add forgotten_filegit commit --amend 撤销提交文件12345678git checkout -- &lt;file&gt; # 取消对文件的修改。还原到最近的版本，废弃本地做的修改。git reset HEAD &lt;file&gt;... # 取消已经暂存的文件。即，撤销先前\"git add\"的操作git reset HEAD^ # 回退所有内容到上一个版本git reset HEAD^ a.py # 回退a.py这个文件的版本到上一个版本git reset –soft HEAD~3 # 向前回退到第3个版本git reset –hard origin/master # 将本地的状态回退到和远程的一样git reset 057d # 回退到某个版本git revert HEAD # 回退到上一次提交的状态，按照某一次的commit完全反向的进行一次commit.(代码回滚到上个版本，并提交git)","tags":[]},{"title":"input radio attr动态赋值问题","date":"2018-10-31T10:04:46.000Z","path":"2018/10/31/input-radio-attr动态赋值问题/","text":"程序环境：easyui+jQuery代码 12&lt;label &gt;&lt;input name=\"Fruit\" type=\"radio\" value=\"苹果\" /&gt;苹果 &lt;/label&gt;&lt;label &gt;&lt;input name=\"Fruit\" type=\"radio\" value=\"西瓜\" /&gt;西瓜 &lt;/label&gt; 最近发现用$(&quot;input[name=&#39;Fruit&#39;][value=&#39;西瓜&#39;]&quot;).attr(&quot;checked&quot;,true);动态赋值没有赋值成功。原来以为是easyui的问题，后来查考文档才发现jQuery中使用prop可以完美解决这个问题。$(&quot;input[name=&#39;Fruit&#39;][value=&#39;西瓜&#39;]&quot;).prop(&quot;checked&quot;,true); 那么，什么时候使用attr，什么时候使用prop？1.添加属性名称该属性就会生效应该使用prop.2.是有true,false两个属性使用prop.3.其他则使用attr","tags":[]},{"title":"jQuery实现获取年月日的一些方法总结","date":"2018-10-31T10:04:23.000Z","path":"2018/10/31/jQuery实现获取年月日的一些方法总结/","text":"用jq来获取当前的时间：123456789$(function()&#123; var myDate = new Date; var year = myDate.getFullYear();//获取当前年 var yue = myDate.getMonth()+1;//获取当前月 var date = myDate.getDate();//获取当前日 var h = myDate.getHours();//获取当前小时数(0-23) var m = myDate.getMinutes();//获取当前分钟数(0-59) var s = myDate.getSeconds();//获取当前秒&#125;)","tags":[]},{"title":"table宽度问题","date":"2018-10-31T10:04:11.000Z","path":"2018/10/31/table宽度问题/","text":"最近在做table列表的时候，出现如果数据过多，导致列表的宽度越来越宽，后来在网上找了很多方法，通过在td里面添加div,通过设置div的宽度来解决。具体代码如下：1234567891011&lt;table border=\"1\" height=\"100\" width=\"500\" bordercolor=\"#ccc\" id=\"startId\" &gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;topicId&lt;/th&gt; &lt;th&gt;创建时间(北京)&lt;/th&gt; &lt;th&gt;测试类型&lt;/th&gt; &lt;th&gt;测试信息&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody id=\"tbMain\"&gt;&lt;/tbody&gt;&lt;/table&gt; 在请求数据的时候，在td里面添加div,设置div的宽度123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051function resultData1(data) &#123; var tbody = document.getElementById('resultMain'); for(var i = 0;i &lt; data.length; i++)&#123; //遍历一下json数据 var trow = getresultRow(data[i]); //定义一个方法,返回tr数据 tbody.appendChild(trow); &#125; &#125; function getresultRow(h) &#123; console.log(h); var row = document.createElement('tr'); //创建行 var idCell = document.createElement('td'); //创建第一列id idCell.innerHTML = h.debug_info.topic_id; //填充数据 row.appendChild(idCell); //加入行 ，下面类似 var ddd = \"\" if (\"create_ts\" in h.debug_info)&#123; var ddd = formatTS2YYYYMMDDHHMMSS(h.create_ts.toString()); &#125; var nameCell = document.createElement('td');//创建第二列name nameCell.innerHTML = ddd; row.appendChild(nameCell); jobCell = document.createElement('td');//创建第三列 jobCell.innerHTML = h.debug_info.type; row.appendChild(jobCell); jobCell = document.createElement('td');//创建第四列 var mesDiv = document.createElement('div'); mesDiv.className = 'mes_div'; #这里添加div，并且设置div的class mesDiv.innerHTML = h.debug_info.message; jobCell.appendChild(mesDiv); row.appendChild(jobCell); jobCell = document.createElement('td');//创建第五列 var div = document.createElement('div'); div.innerHTML = h.debug_info.result; jobCell.appendChild(div); row.appendChild(jobCell); return row; //返回tr数据 &#125;&lt;style&gt; .mes_div&#123; width: 100px; &#125;&lt;/style&gt;","tags":[]},{"title":"easyui弹窗窗口无法移动","date":"2018-10-31T10:03:56.000Z","path":"2018/10/31/easyui弹窗窗口无法移动/","text":"最近在使用easyui 弹出窗口的时候，发现窗口无法拖动。具体代码如下123456function openLookUp(url, title) &#123; lookUpWin.dialogFrameHtml(url); if(title) &#123; lookUpWin.panel(&#123;title: title&#125;); &#125;&#125; 后来经过对比是因为修改title引起的，这个easyui 还没有解决这个bug。知道是哪出现问题，后面就好办了，具体代码如下：1234function openLookUp(url, title) &#123; lookUpWin.dialogFrameHtml(url); $('.panel-title')[0].innerHTML=title;&#125;","tags":[]},{"title":"fetch的使用","date":"2018-10-31T10:03:35.000Z","path":"2018/10/31/fetch的使用/","text":"最近的工作过程中，在做js调取接口的时候，使用了fetch，原来是只知道fetch，但是没有怎么使用过。正好最近使用到，所以对其详细了解了下。 fetch的基本方式123456789101112131415fetch(url,&#123; method:'GET', # 'POST','PUT','DELETE' headers:&#123; 'Content-Type':'application/json', //'application/x-www-form-urlencoded' 'Accept':'application/json' &#125;, body:JSON.stringfiy(body)&#125;).then((res)=&gt;&#123; return res.json() //返回一个Promise,解析成JSON,具体请看下面返回的数据&#125;).then(function(res)&#123; console.log(res) //获取json数据&#125;).catch(function(error)&#123; console.log(error) //请求错误时返回&#125;) 返回的数据1234567891011121314res.arrayBuffer()读取 res对象并且将它设置为已读（因为Responses对象被设置为了 stream 的方式，所以它们只能被读取一次） ,并返回一个被解析为ArrayBuffer格式的promise对象res.blob()读取 res对象并且将它设置为已读（因为Responses对象被设置为了 stream 的方式，所以它们只能被读取一次） ,并返回一个被解析为Blob格式的promise对象res.formData()读取res对象并且将它设置为已读（因为Responses对象被设置为了 stream 的方式，所以它们只能被读取一次） ,并返回一个被解析为FormData格式的promise对象res.json()读取 res对象并且将它设置为已读（因为Responses对象被设置为了 stream 的方式，所以它们只能被读取一次） ,并返回一个被解析为JSON格式的promise对象res.text()读取 res对象并且将它设置为已读（因为Responses对象被设置为了 stream 的方式，所以它们只能被读取一次） ,并返回一个被解析为USVString格式的promise对象 强制带Cookie默认情况下, fetch不会从服务端发送或接收任何 cookies, 如果站点依赖于维护一个用户会话，则导致未经认证的请求(要发送 cookies，必须发送凭据头). 12345678910fetch(url, &#123; method: 'GET', credentials: 'include' // 强制加入凭据头 &#125;) .then((res)=&gt;&#123; return res.text() &#125;) .then((res)=&gt;&#123; console.log(res) &#125;)","tags":[]},{"title":"ansible自动化部署","date":"2018-10-31T09:58:59.000Z","path":"2018/10/31/自动化部署/","text":"安装Ansible可通过 “pip” 安装(安装和管理Python包的工具),若你还没有安装 pip,可执行如下命令安装: 1$ sudo easy_install pip 然后安装Ansible:1$ sudo pip install ansible 如果你是在 OS X Mavericks 上安装,编译器可能或告警或报错,可通过如下设置避免这种情况:1$ sudo CFLAGS=-Qunused-arguments CPPFLAGS=-Qunused-arguments pip install ansible 使用 virtualenv 的读者可通过 virtualenv 安装 Ansible, 然而我们建议不用这样做,直接在全局安装 Ansible.不要使用 easy_install 直接安装 ansible. 配置hosts修改/etc/ansible/hosts 全局hosts文件，没有的话自己创建1$ vim /etc/ansible/hosts 12345[localhost] # 如果服务器使用密码登录就用这个方式保存密码，避免每次输入127.0.0.1 ansible_ssh_pass=your_pass ansible_ssh_user=your_name[prod] # 如果服务器使用sshkey登陆（推荐使用）prod.server.org ansible_ssh_user=your_name ansible_ssh_private_key_file=key_path 具体的是 prod.server.org是IP, your_pass是服务器的密码,your_name是服务器的名字, key_path是用key登录. 第一条命令首先执行ping,看是否可以连接上服务器 12345678910$ ansible all -m ping127.0.0.1 | SUCCESS =&gt; &#123; \"changed\": false, \"ping\": \"pong\"&#125;prod.server.org | SUCCESS =&gt; &#123; \"changed\": false, \"ping\": \"pong\"&#125; 得到如上样式结果即为正确,另外执行 ansible prod -m ping 可以针对某一个服务器组进行操作 这时候说明你的ansible已经跑通，下面可以进行其他操作","tags":[]},{"title":"ansible sshpass的部署问题","date":"2018-10-31T09:58:50.000Z","path":"2018/10/31/sshpass的部署问题/","text":"在使用ansible配置好hosts，运行ping1$ ansible all -m ping 发现出现错误，错误原因是需要安装sshpass。就用yum去安装，因为用的是mac，导致没有安装yum，所以就想用brew去安装，直接使用brew install sshpass,发现发现错误。 12345Shell代码 收藏代码$ brew install sshpass Error: No available formula for sshpass We won't add sshpass because it makes it too easy for novice SSH users to ruin SSH's security. 使用homebrew强制安装 1brew install https://raw.github.com/eugeneoden/homebrew/eca9de1/Library/Formula/sshpass.rb 就可以成功了","tags":[]},{"title":"ansible playbook","date":"2018-10-31T09:58:40.000Z","path":"2018/10/31/playbook/","text":"Playbooks 是 Ansible的配置,部署,编排语言.他们可以被描述为一个需要希望远程主机执行命令的方案,或者一组IT程序运行的命令集合. 一个playbook就是一个YAML文件，所以playbook文件一般都以.yml结尾，一个playbook文件由一个或多个play组成，每个play定义了在一个或多个远程主机上执行的一系列的task，其中每个task一般就是调用一个ansible的模块，如调用copy模块复制文件到远程主机或调用shell模块执行命令。 简单的配置配置deploy.yml完成进入远程服务器的某个目录并执行git pull操作 1234561 - hosts: wxnacy # 它会默认使用/etc/ansible/hosts 中配置的服务器组名 也可以单独设置hosts地址2 tasks:3 - name: cd path and git pull # 命令名称4 shell: git pull # 执行命令5 args:6 chdir: ~/workdir # 进入目录 运行 123456$ ansible-playbook deploy.ymlPLAY [wxnacy] *************************************************************************TASK [cd path and git pull] *************************************************************************ok: [wxnacy.server.org]PLAY RECAP *************************************************************************wxnacy.server.org : ok=2 changed=1 unreachable=0 failed=0 执行完运行命令ansible会在webservers组中依次执行tasks，返回以上样式结果极为成功，结果通过红黄绿三种颜色标明了不同的执行结果，红色表示有task执行失败，黄色表示改变了远程主机状态。 可以查看相关文章shell - Execute commands in nodesAll modulesAnsible playbook简介与配置","tags":[]},{"title":"ansible 自动化","date":"2018-10-31T09:58:30.000Z","path":"2018/10/31/自动化/","text":"ansible 自动化部署ansible playbookansible sshpass的部署问题 ansible介绍国内的中文站点：Ansible中文权威指南 ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。 ansible是基于 paramiko 开发的,并且基于模块化工作，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。ansible不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。ansible目前已经已经被红帽官方收购，是自动化运维工具中大家认可度最高的，并且上手容易，学习简单。是每位运维工程师必须掌握的技能之一。ansible特点123456781、部署简单，只需在主控端部署Ansible环境，被控端无需做任何操作；2、默认使用SSH协议对设备进行管理；3、有大量常规运维操作模块，可实现日常绝大部分操作。4、配置简单、功能强大、扩展性强；5、支持API及自定义模块，可通过Python轻松扩展；6、通过Playbooks来定制强大的配置、状态管理；7、轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；8、提供一个功能强大、操作性强的Web管理界面和REST API接口——AWX平台。","tags":[]},{"title":"item2快捷键的应用","date":"2018-10-31T09:57:44.000Z","path":"2018/10/31/item2快捷键的应用/","text":"使用item2已经一段时间了，发现item2和苹果自带的终端工具Terminal相比，简直完爆它。下面是一些基础的快捷键 标签12新建标签 command + t切换标签 command + 左右方向键 或者 command+数字 分屏123垂直分屏：command + d水平分屏：command + shift + d切换屏幕：command + [ 或 command + ] 共同标签或者分屏的快键键为12关闭标签或者分屏：command + w切换全屏：command + enter command 相关的快捷键1234查找：command + f查看历史命令：command + ;查看剪贴板历史：command + shift + h清屏：command + r control 相关的快捷键1234567891011清除当前行：ctrl + u到行首：ctrl + a到行尾：ctrl + e前进后退：ctrl + f/b (翻页)上一条命令：ctrl + p搜索命令历史：ctrl + r删除当前光标的字符：ctrl + d删除光标之前的字符：ctrl + h删除光标之前的单词：ctrl + w删除到文本末尾：ctrl + k交换光标处文本：ctrl + t","tags":[]},{"title":"Mac下pyenv与pyenv-virtualenv的安装","date":"2018-10-31T09:56:54.000Z","path":"2018/10/31/Mac下pyenv与pyenv-virtualenv的安装/","text":"在 Mac 上使用 brew 可以很方便的安装 pyenv 1、安装1brew install pyenv 2、配置打开vim ~/.bash_profile，在最后写入12345export PYENV_ROOT=\"$HOME/.pyenv\"export PATH=\"$PYENV_ROOT/bin:$PATH\"if which pyenv &gt; /dev/null; then eval \"$(pyenv init -)\";fi 配置完以后别忘了source ~/.bash_profile，使配置生效 3、使用1234567891011#查看可安装的版本pyenv install --list#安装python版本pyenv install 3.5.0#查看当前已安装的python版本pyenv versions#重置版本设置 (只有 pyenv shell 和 pyenv local 命令有--unset参数)pyenv shell --unsetpyenv local --unset#卸载版本pyenv uninstall 3.5.0 设置python版本12345678# 对所有的Shell全局有效，会把版本号写入到~/.pyenv/version文件中pyenv global 3.5.0# 只对当前目录有效，会在当前目录创建.python-version文件pyenv local 3.5.0# 只在当前会话有效pyenv shell 3.5.0 这个时候，pyenv已经安装成功了，下面咱们安装设置python版本 pyenv-virtualenv pyenv-virtualenv 是pyenv的插件，为pyenv设置的python版本提供隔离的虚拟环境，设置虚拟环境后，在当前目录下面安装的第三方库都不会影响其他环境 1、安装1brew install pyenv-virtualenv 2、配置打开vim ~/.bash_profile，在最后写入123if which pyenv-virtualenv-init &gt; /dev/null; then eval \"$(pyenv virtualenv-init -)\";fi 配置完以后别忘了source ~/.bash_profile，使配置生效 3、使用123456789101112131415161718192021222324#从当前版本创建virtualenvpyenv virtualenv env350#指定版本创建virtualenv#pyenv virtualenv 版本号 虚拟环境名pyenv virtualenv 3.6.3 xxx-3.6.3#查看已创建的virtualenvpyenv versions#激活和停用virtualenv# 手动激活pyenv activate 虚拟环境名pyenv deactivate# 自动激活# 使用pyenv local 虚拟环境名# 会把`虚拟环境名`写入当前目录的.python-version文件中# 关闭自动激活 -&gt; pyenv deactivate# 启动自动激活 -&gt; pyenv activate xxx-3.6.3pyenv local xxx-3.6.3#删除现有virtualenvpyenv uninstall 虚拟环境名","tags":[]},{"title":"如何杀死一个已经detached的screen会话","date":"2018-10-31T09:56:16.000Z","path":"2018/10/31/如何杀死一个已经detached的screen会话/","text":"如果想杀死一个已经detached的screen会话，可以使用以下命令： 方法一：1screen -X -S [session # you want to kill] quit 比如12345678910[root@localhost ~]# screen -lsThere are screens on: 9975.admin (Detached) 4588.scheduler (Detached)[root@localhost ~]# screen -X -S 4588 quit[root@localhost ~]# screen -lsThere is a screen on: 9975.pts-0.localhost (Detached)1 Socket in /var/run/screen/S-root. 可以看到，4588会话已经没有了。 方法二：激活screen： screen -r session_name 并利用exit退出并kiil掉session。","tags":[]},{"title":"Linux 查看硬盘容量，Linux系统是Centos还是Ubuntu","date":"2018-10-31T09:55:04.000Z","path":"2018/10/31/Linux的常用命令/","text":"查看硬盘使用了多少容量 123456789101112131415161718[root@iZ2ze32 ~]# df -hl文件系统 容量 已用 可用 已用% 挂载点/dev/vda1 40G 3.7G 34G 10% /devtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 1.9G 364K 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgrouptmpfs 380M 0 380M 0% /run/user/0[root@iZ2ze326 ~]# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/vda1 41151808 3867112 35171264 10% /devtmpfs 1931336 0 1931336 0% /devtmpfs 1940844 0 1940844 0% /dev/shmtmpfs 1940844 364 1940480 1% /runtmpfs 1940844 0 1940844 0% /sys/fs/cgrouptmpfs 388172 0 388172 0% /run/user/0 查看Linux系统是Centos还是Ubuntu输入命令 lsb_release -a 1234567891011## 现在有的系统可以用这个查出是否是centos还是ubuntu，如阿里云[root@iZ2ze326 ~]# lsb_release -aLSB Version: :core-4.1-amd64:core-4.1-noarchDistributor ID: CentOSDescription: CentOS Linux release 7.4.1708 (Core)Release: 7.4.1708Codename: Core## 而在公司的本地服务器，却出现这种情况[root@hardwareupdate ~]# lsb_release -a-bash: lsb_release: command not found 当这个命令不管用的时候，可以使用命令 cat /etc/redhat-release 1234567## 在ubuntu中会出现[root@hardwareupdate ~]# cat /etc/redhat-release-bash: /etc/redhat-release: command not found## 在centos中显示[root@hardwareupdate ~]# cat /etc/redhat-releaseCentOS release 6.10 (Final) 查看Linux 某些程序进程 ps aux比如：123[root@iZ2ze3269b etc]# ps aux | grep mysqlroot 2371 0.0 0.0 112676 980 pts/0 S+ 14:34 0:00 grep --color=auto mysqlmysql 10810 0.1 9.4 1599384 367788 ? Sl 10月11 13:13 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid","tags":[]},{"title":"Centos7安装mysql","date":"2018-10-31T09:53:56.000Z","path":"2018/10/31/Centos7安装mysql/","text":"mysql 官方下载地址：https://dev.mysql.com/downloads/repo/yum/查找最新的 rpm下载1$ wget https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm 确定 md5 值12$ md5sum mysql80-community-release-el7-1.noarch.rpm739dc44566d739c5d7b893de96ee6848 mysql80-community-release-el7-1.noarch.rpm 安装1$ sudo rpm -ivh mysql80-community-release-el7-1.noarch.rpm 因为现今mysql已经更新到8.0以上了，所以可以根据需求是用5.5以上的某一个版本还是8.0等 8.0版本12$ sudo yum update -y$ sudo yum install -y mysql-server 5.7版本查看可安装的版本12345678910111213141516171819$ yum repolist all | grep mysqlmysql-cluster-7.5-community/x86_64 MySQL Cluster 7.5 Community disabledmysql-cluster-7.5-community-source MySQL Cluster 7.5 Community - disabledmysql-cluster-7.6-community/x86_64 MySQL Cluster 7.6 Community disabledmysql-cluster-7.6-community-source MySQL Cluster 7.6 Community - disabledmysql-connectors-community/x86_64 MySQL Connectors Community enabled: 51mysql-connectors-community-source MySQL Connectors Community - S disabledmysql-tools-community/x86_64 MySQL Tools Community enabled: 63mysql-tools-community-source MySQL Tools Community - Source disabledmysql-tools-preview/x86_64 MySQL Tools Preview disabledmysql-tools-preview-source MySQL Tools Preview - Source disabledmysql55-community/x86_64 MySQL 5.5 Community Server disabledmysql55-community-source MySQL 5.5 Community Server - S disabledmysql56-community/x86_64 MySQL 5.6 Community Server disabledmysql56-community-source MySQL 5.6 Community Server - S disabledmysql57-community/x86_64 MySQL 5.7 Community Server disabledmysql57-community-source MySQL 5.7 Community Server - S disabledmysql80-community/x86_64 MySQL 8.0 Community Server enabled: 17mysql80-community-source MySQL 8.0 Community Server - S disabled 因为默认的是8.0的版本，所以要选择5.7的版本12$ sudo yum-config-manager --disable mysql80-community$ sudo yum-config-manager --enable mysql57-community 下载1$ sudo yum install mysql-community-server 启动1$ sudo systemctl start mysqld 查看运行状态123456789101112131415$ sudo systemctl status mysqld● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Fri 2018-06-01 10:35:58 UTC; 1h 39min ago Docs: man:mysqld(8) [http://dev.mysql.com/doc/refman/en/using-systemd.html](http://dev.mysql.com/doc/refman/en/using-systemd.html) Process: 7474 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 7542 (mysqld) Status: \"SERVER_OPERATING\" CGroup: /system.slice/mysqld.service └─7542 /usr/sbin/mysqldJun 01 10:35:49 bogon systemd[1]: Starting MySQL Server...Jun 01 10:35:58 bogon systemd[1]: Started MySQL Server.&lt;/pre&gt; 这时候mysql已经安装成功了，下面是配置 配置Mysql 在安装时会默认设置一个随机密码，需要在第一次使用时修改 查看密码12$ sudo grep 'temporary password' /var/log/mysqld.log2018-06-01T10:35:51.710406Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: Vq9wOQ&amp;trFs* 首先使用默认密码登录 Mysql1$ mysql -uroot -p 查看所有 validatei_password123456789101112131415161718192021mysql&gt; SHOW VARIABLES LIKE 'validate_password%';+--------------------------------------+-------+| Variable_name | Value |+--------------------------------------+-------+| validate_password.check_user_name | ON || validate_password.dictionary_file | || validate_password.length | 8 || validate_password.mixed_case_count | 1 || validate_password.number_count | 1 || validate_password.policy | MEDIUM|| validate_password.special_char_count | 1 || validate_password_check_user_name | ON || validate_password_dictionary_file | || validate_password_length | 8 || validate_password_mixed_case_count | 1 || validate_password_number_count | 1 || validate_password_policy | MEDIUM|| validate_password_special_char_count | 1 |+--------------------------------------+-------+14 rows in set (0.00 sec) 这时候会看到mysql的密码策略123456789101112There are three levels of password validation policy:# 长度大于 8 位LOW Length &gt;= 8# 长度大于 8 位，数字，混合大小写和特殊字符MEDIUM Length &gt;= 8, numeric, mixed case, and special characters# 长度大于 8 位，数字，混合大小写，特殊字符和字典STRONG Length &gt;= 8, numeric, mixed case, special characters and dictionaryPlease enter 0 = LOW, 1 = MEDIUM and 2 = STRONG:他们分别对应了数字 0, 1, 2，Mysql 默认的等级为 MEDIUM，所以输入普通的密码就会报错，怎样修改策略呢？ 所以当出现下面的错误的时候，有可能就是因为密码强度的问题1Failed! Error: Your password does not satisfy the current policy requirements 所以可以根据你想达到的安全程度，设置密码，比如我这里设置为最低:123set global validate_password_policy=0;## 如果你不想让长度必须大于 8 位，也可以改为 4，这是最低长度set global validate_password_length=4; 随后修改mysql密码:1set password=password('111111'); 最后可以将访问权限全部对外开放1GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'wxnacy' WITH GRANT OPTION; 也可以指定 ip 开放1GRANT ALL PRIVILEGES ON *.* TO 'root'@'192.168.33.11' IDENTIFIED BY 'wxnacy' WITH GRANT OPTION; 最后使配置生效1flush privileges; mysql 新设置用户或更改密码后需用flush privileges刷新MySQL的系统权限相关表，否则会出现拒绝访问，还有一种方法，就是重新启动mysql服务器，来使新设置生效","tags":[]},{"title":"Supervisor重新加载配置启动新的进程","date":"2018-10-31T09:52:57.000Z","path":"2018/10/31/Supervisor重新加载配置启动新的进程/","text":"一、添加好配置文件后二、更新新的配置到supervisord1supervisorctl update 三、重新启动配置中的所有程序1supervisorctl reload 四、启动某个进程(program_name=你配置中写的程序名称)1supervisorctl start program_name 五、查看正在守候的进程1supervisorctl 六、停止某一进程 (program_name=你配置中写的程序名称)1pervisorctl stop program_name 七、重启某一进程 (program_name=你配置中写的程序名称)1supervisorctl restart program_name 八、停止全部进程(显示用stop停止掉的进程，用reload或者update都不会自动重启)1supervisorctl stop all 参考：Supervisor重新加载配置启动新的进程","tags":[{"name":"Supervisor","slug":"Supervisor","permalink":"http://yoursite.com/tags/Supervisor/"}]},{"title":"mac查看端口占用进程以及强制清理进程","date":"2018-10-31T09:47:30.000Z","path":"2018/10/31/mac查看端口占用进程以及强制清理进程/","text":"查看5001段口被占用进程lsof -i:5001： 12345678910111213localhost:My$ lsof -i:5001COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME[Python](http://lib.csdn.net/base/python \"Python知识库\") 6320 zhaozeguang 3u IPv4 0x82d867c5ec4904d9 0t0 TCP localhost:51816-&gt;localhost:commplex-link (CLOSED)[python](http://lib.csdn.net/base/python \"Python知识库\") 6323 zhaozeguang 3u IPv4 0x82d867c5ec4916e9 0t0 TCP localhost:51820-&gt;localhost:commplex-link (CLOSED)Python 6327 zhaozeguang 3u IPv4 0x82d867c5ed8b52c9 0t0 TCP localhost:51828-&gt;localhost:commplex-link (CLOSED)Python 6328 zhaozeguang 3u IPv4 0x82d867c5edcf04d9 0t0 TCP localhost:51835-&gt;localhost:commplex-link (CLOSED)Python 6330 zhaozeguang 3u IPv4 0x82d867c5e27d06e9 0t0 TCP localhost:51836-&gt;localhost:commplex-link (CLOSED) kill掉无用进程 kill PID1localhost:My$ kill 6327 6328 6330","tags":[]}]